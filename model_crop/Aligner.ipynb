{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, random, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.data import imread\n",
    "from skimage.io import imshow,imsave\n",
    "from skimage import img_as_float\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.util import crop\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "TEST_DIR = '../data/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "modelStr = 'Crop'\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 64\n",
    "LearningRate = 1e-4\n",
    "le = LabelEncoder()\n",
    "le.fit(FISH_CLASSES)\n",
    "le.transform(FISH_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成图像随机变换矩阵\n",
    "#modified from code https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py\n",
    "\n",
    "def transform_matrix_offset_center(matrix, w, h):\n",
    "    center_x = float(w) / 2 + 0.5\n",
    "    center_y = float(h) / 2 + 0.5\n",
    "    #图像center移到原点，进行rotation和shear\n",
    "    offset_matrix = np.array([[1, 0, center_x], [0, 1, center_y], [0, 0, 1]])\n",
    "    #移回来\n",
    "    reset_matrix = np.array([[1, 0, -center_x], [0, 1, -center_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(reset_matrix, matrix), offset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def random_transform_matrix(image,\n",
    "                            rotation_range=0.,\n",
    "                            width_shift_range=0.,\n",
    "                            height_shift_range=0.,\n",
    "                            shear_range=0.,\n",
    "                            zoom_range=0.,\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False):\n",
    "    \n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "       \n",
    "    #图像上下翻转\n",
    "    hflip_matrix=np.eye(3)\n",
    "    if horizontal_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            print(\"horizontal_flip\")\n",
    "            hflip_matrix = np.array([[-1, 0, w],\n",
    "                                     [0, 1, 0],\n",
    "                                     [0, 0, 1]])\n",
    "    #图像左右翻转                              \n",
    "    vflip_matrix=np.eye(3)\n",
    "    if vertical_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            print(\"vertical_flip\")\n",
    "            vflip_matrix = np.array([[1, 0, 0],\n",
    "                                     [0, -1, h],\n",
    "                                     [0, 0, 1]])\n",
    "    #图像顺时针旋转theta       \n",
    "    if rotation_range:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rotation_range, rotation_range)\n",
    "    else:\n",
    "        theta = 0\n",
    "    print(\"theta =\",theta)\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    \n",
    "    #图像往正轴移动tx，ty\n",
    "    if height_shift_range:\n",
    "        ty = np.random.uniform(-height_shift_range, height_shift_range) * h\n",
    "    else:\n",
    "        ty = 0\n",
    "\n",
    "    if width_shift_range:\n",
    "        tx = np.random.uniform(-width_shift_range, width_shift_range) * w\n",
    "    else:\n",
    "        tx = 0\n",
    "    print(\"tx =\",tx)\n",
    "    print(\"ty =\",ty)\n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty],\n",
    "                                   [0, 0, 1]])\n",
    "    \n",
    "    #图像顺时针shear\n",
    "    if shear_range:\n",
    "        shear = np.random.uniform(-shear_range, shear_range)\n",
    "    else:\n",
    "        shear = 0\n",
    "    print(\"shear =\",shear)\n",
    "    shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                             [0, np.cos(shear), 0],\n",
    "                             [0, 0, 1]])\n",
    "    \n",
    "    #以center为中心图像放大zx，zy\n",
    "    if np.isscalar(zoom_range):\n",
    "        zoom_range = [1 - zoom_range, 1 + zoom_range]\n",
    "    elif len(zoom_range) == 2:\n",
    "        zoom_range = [zoom_range[0], zoom_range[1]]\n",
    "    else:\n",
    "        raise ValueError('zoom_range should be a float or '\n",
    "                         'a tuple or list of two floats. '\n",
    "                         'Received arg: ', zoom_range)\n",
    "            \n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    print(\"zx =\",zx)\n",
    "    print(\"zy =\",zy)\n",
    "    zoom_matrix = np.array([[zx, 0, (1-zx)*w/2.],\n",
    "                            [0, zy, (1-zy)*h/2.],\n",
    "                            [0, 0, 1]])\n",
    "    #transform_matrix = zoom_matrix\n",
    "    transform_matrix = np.dot(shear_matrix, rotation_matrix)\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, w, h)\n",
    "    transform_matrix = np.dot(np.dot(np.dot(np.dot(translation_matrix, \n",
    "                                                   zoom_matrix), \n",
    "                                            transform_matrix), \n",
    "                                     vflip_matrix), \n",
    "                              hflip_matrix)\n",
    "    return transform_matrix[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'class': 'point', 'y': 155.0, 'x': 409.0}]</td>\n",
       "      <td>image</td>\n",
       "      <td>image2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'class': 'point', 'y': 342.8499725255559, 'x...</td>\n",
       "      <td>image</td>\n",
       "      <td>img_00003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'class': 'point', 'y': 606.0901688065899, 'x...</td>\n",
       "      <td>image</td>\n",
       "      <td>img_00010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'class': 'point', 'y': 514.0046459216107, 'x...</td>\n",
       "      <td>image</td>\n",
       "      <td>img_00012.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'class': 'point', 'y': 359.55000000000035, '...</td>\n",
       "      <td>image</td>\n",
       "      <td>img_00015.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotations  class       filename\n",
       "0       [{'class': 'point', 'y': 155.0, 'x': 409.0}]  image     image2.jpg\n",
       "1  [{'class': 'point', 'y': 342.8499725255559, 'x...  image  img_00003.jpg\n",
       "2  [{'class': 'point', 'y': 606.0901688065899, 'x...  image  img_00010.jpg\n",
       "3  [{'class': 'point', 'y': 514.0046459216107, 'x...  image  img_00012.jpg\n",
       "4  [{'class': 'point', 'y': 359.55000000000035, '...  image  img_00015.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2.jpg\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a272b7701eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 raise ValueError(\"Location based indexing can only have [%s] \"\n\u001b[1;32m    144\u001b[0m                                  \"types\" % self._valid_types)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "labels = pd.read_json('../data/annotation/alb_labels.json')\n",
    "img_filename = labels.iloc[0,2]\n",
    "print(img_filename)\n",
    "l1 = pd.DataFrame((labels[labels.filename==img_filename].annotations).iloc[0])\n",
    "x_head = l1.iloc[0,1]\n",
    "y_head = l1.iloc[0,2]\n",
    "x_tail = l1.iloc[1,1]\n",
    "y_tail = l1.iloc[1,2]\n",
    "\n",
    "image = imread(TRAIN_DIR+'ALB/'+img_filename)\n",
    "rescale = 1./255,\n",
    "image = image*rescale\n",
    "h, w = image.shape[0], image.shape[1]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.plot(x_head, y_head,'rs')\n",
    "plt.plot(x_tail, y_tail,'gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = random_transform_matrix(image,\n",
    "                            rotation_range=20,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.1,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True)\n",
    "image_transformed = cv2.warpAffine(image, M, (w, h), borderMode=1)\n",
    "head_transformed = np.dot(M,np.array([x_head,y_head,1]))\n",
    "tail_transformed = np.dot(M,np.array([x_tail,y_tail,1]))\n",
    "x_head_transformed = head_transformed[0]\n",
    "y_head_transformed = head_transformed[1]\n",
    "x_tail_transformed = tail_transformed[0]\n",
    "y_tail_transformed = tail_transformed[1]\n",
    "\n",
    "plt.imshow(image_transformed)\n",
    "if 0<=x_head_transformed<=w and 0<=y_head_transformed<=h:\n",
    "    plt.plot(x_head_transformed, y_head_transformed,'rs')\n",
    "if 0<=x_tail_transformed<=w and 0<=y_tail_transformed<=h:\n",
    "    plt.plot(x_tail_transformed, y_tail_transformed,'gs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center = ( (x_head_transformed+x_tail_transformed) / 2,(y_head_transformed+y_tail_transformed) / 2)\n",
    "fish_length = np.sqrt((x_tail_transformed-x_head_transformed)**2+\n",
    "                      (y_tail_transformed-y_head_transformed)**2)\n",
    "image_cropped = image_transformed[(max((center[1]-fish_length/1.8),0)):(max((center[1]+fish_length/1.8),0)) ,\n",
    "                  (max((center[0]- fish_length/1.8),0)):(max((center[0]+fish_length/1.8),0))]\n",
    "\n",
    "plt.imshow(image_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_resized = resize(image_transformed,(ROWS,COLS))\n",
    "plt.imshow(image_resized)\n",
    "x_ratio = float(COLS)/w\n",
    "y_ratio = float(ROWS)/h\n",
    "print(x_ratio,y_ratio)\n",
    "head_resized = [head_transformed[0]*x_ratio,head_transformed[1]*y_ratio]\n",
    "tail_resized = [tail_transformed[0]*x_ratio,tail_transformed[1]*y_ratio]\n",
    "plt.plot(head_resized[0], head_resized[1],'rs')\n",
    "plt.plot(tail_resized[0], tail_resized[1],'gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "crop_classes=FISH_CLASSES[:]\n",
    "crop_classes.remove('NoF')\n",
    "crop_classes\n",
    "\n",
    "images = []\n",
    "y_train = []\n",
    "\n",
    "for e in range(100):\n",
    "    for c in crop_classes:\n",
    "        labels = pd.read_json('../data/annotation/'+c.lower()+'_labels.json')\n",
    "        for i in range(len(labels)):\n",
    "            try:\n",
    "                img_filename = labels.iloc[i,2]\n",
    "                print(img_filename)\n",
    "                l1 = pd.DataFrame((labels[labels.filename==img_filename].annotations).iloc[0])\n",
    "                image = imread(TRAIN_DIR+c+'/'+img_filename)\n",
    "                images.append(get_rotated_cropped_fish(image,np.floor(l1.iloc[0,1]),np.floor(l1.iloc[0,2]),np.floor(l1.iloc[1,1]),np.floor(l1.iloc[1,2])))\n",
    "                print('success')\n",
    "                y_train.append(c)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "model.train_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from original images. Generating data_train_annotation_224_224.pickle.\n",
      "image2.jpg\n",
      "fail\n",
      "img_00003.jpg\n",
      "success\n",
      "img_00010.jpg\n",
      "success\n",
      "img_00012.jpg\n",
      "success\n",
      "img_00015.jpg\n",
      "success\n",
      "img_00019.jpg\n",
      "success\n",
      "img_00020.jpg\n",
      "success\n",
      "img_00029.jpg\n",
      "success\n",
      "img_00032.jpg\n",
      "success\n",
      "img_00037.jpg\n",
      "success\n",
      "img_00038.jpg\n",
      "success\n",
      "img_00039.jpg\n",
      "success\n",
      "img_00041.jpg\n",
      "success\n",
      "img_00043.jpg\n",
      "success\n",
      "img_00045.jpg\n",
      "success\n",
      "img_00055.jpg\n",
      "success\n",
      "img_00057.jpg\n",
      "success\n",
      "img_00074.jpg\n",
      "success\n",
      "img_00085.jpg\n",
      "success\n",
      "img_00090.jpg\n",
      "success\n",
      "img_00097.jpg\n",
      "success\n",
      "img_00110.jpg\n",
      "success\n",
      "img_00121.jpg\n",
      "success\n",
      "img_00130.jpg\n",
      "success\n",
      "img_00134.jpg\n",
      "success\n",
      "img_00136.jpg\n",
      "success\n",
      "img_00154.jpg\n",
      "success\n",
      "img_00156.jpg\n",
      "success\n",
      "img_00163.jpg\n",
      "success\n",
      "img_00177.jpg\n",
      "success\n",
      "img_00186.jpg\n",
      "success\n",
      "img_00187.jpg\n",
      "success\n",
      "img_00188.jpg\n",
      "success\n",
      "img_00191.jpg\n",
      "success\n",
      "img_00193.jpg\n",
      "success\n",
      "img_00197.jpg\n",
      "success\n",
      "img_00201.jpg\n",
      "success\n",
      "img_00206.jpg\n",
      "success\n",
      "img_00208.jpg\n",
      "success\n",
      "img_00209.jpg\n",
      "success\n",
      "img_00211.jpg\n",
      "success\n",
      "img_00215.jpg\n",
      "success\n",
      "img_00219.jpg\n",
      "success\n",
      "img_00227.jpg\n",
      "success\n",
      "img_00228.jpg\n",
      "success\n",
      "img_00233.jpg\n",
      "success\n",
      "img_00236.jpg\n",
      "success\n",
      "img_00237.jpg\n",
      "success\n",
      "img_00239.jpg\n",
      "success\n",
      "img_00248.jpg\n",
      "success\n",
      "img_00264.jpg\n",
      "success\n",
      "img_00269.jpg\n",
      "success\n",
      "img_00270.jpg\n",
      "success\n",
      "img_00274.jpg\n",
      "success\n",
      "img_00275.jpg\n",
      "success\n",
      "img_00277.jpg\n",
      "success\n",
      "img_00278.jpg\n",
      "success\n",
      "img_00281.jpg\n",
      "success\n",
      "img_00288.jpg\n",
      "success\n",
      "img_00290.jpg\n",
      "success\n",
      "img_00291.jpg\n",
      "success\n",
      "img_00294.jpg\n",
      "success\n",
      "img_00295.jpg\n",
      "success\n",
      "img_00296.jpg\n",
      "success\n",
      "img_00299.jpg\n",
      "success\n",
      "img_00300.jpg\n",
      "success\n",
      "img_00301.jpg\n",
      "success\n",
      "img_00317.jpg\n",
      "success\n",
      "img_00319.jpg\n",
      "success\n",
      "img_00327.jpg\n",
      "success\n",
      "img_00337.jpg\n",
      "success\n",
      "img_00338.jpg\n",
      "success\n",
      "img_00341.jpg\n",
      "success\n",
      "img_00342.jpg\n",
      "success\n",
      "img_00344.jpg\n",
      "success\n",
      "img_00351.jpg\n",
      "success\n",
      "img_00353.jpg\n",
      "success\n",
      "img_00356.jpg\n",
      "success\n",
      "img_00361.jpg\n",
      "success\n",
      "img_00366.jpg\n",
      "success\n",
      "img_00369.jpg\n",
      "success\n",
      "img_00381.jpg\n",
      "success\n",
      "img_00384.jpg\n",
      "success\n",
      "img_00385.jpg\n",
      "success\n",
      "img_00396.jpg\n",
      "success\n",
      "img_00401.jpg\n",
      "success\n",
      "img_00403.jpg\n",
      "success\n",
      "img_00415.jpg\n",
      "success\n",
      "img_00421.jpg\n",
      "success\n",
      "img_00425.jpg\n",
      "success\n",
      "img_00447.jpg\n",
      "success\n",
      "img_00451.jpg\n",
      "success\n",
      "img_00457.jpg\n",
      "success\n",
      "img_00461.jpg\n",
      "success\n",
      "img_00466.jpg\n",
      "success\n",
      "img_00482.jpg\n",
      "success\n",
      "img_00490.jpg\n",
      "success\n",
      "img_00496.jpg\n",
      "success\n",
      "img_00502.jpg\n",
      "success\n",
      "img_00507.jpg\n",
      "success\n",
      "img_00508.jpg\n",
      "success\n",
      "img_00509.jpg\n",
      "success\n",
      "img_00523.jpg\n",
      "success\n",
      "img_00525.jpg\n",
      "success\n",
      "img_00526.jpg\n",
      "success\n",
      "img_00544.jpg\n",
      "success\n",
      "img_00545.jpg\n",
      "success\n",
      "img_00546.jpg\n",
      "success\n",
      "img_00555.jpg\n",
      "success\n",
      "img_00558.jpg\n",
      "success\n",
      "img_00561.jpg\n",
      "success\n",
      "img_00562.jpg\n",
      "success\n",
      "img_00568.jpg\n",
      "fail\n",
      "img_00570.jpg\n",
      "success\n",
      "img_00576.jpg\n",
      "success\n",
      "img_00579.jpg\n",
      "success\n",
      "img_00592.jpg\n",
      "success\n",
      "img_00594.jpg\n",
      "success\n",
      "img_00595.jpg\n",
      "success\n",
      "img_00596.jpg\n",
      "success\n",
      "img_00605.jpg\n",
      "success\n",
      "img_00607.jpg\n",
      "success\n",
      "img_00617.jpg\n",
      "success\n",
      "img_00624.jpg\n",
      "success\n",
      "img_00626.jpg\n",
      "success\n",
      "img_00632.jpg\n",
      "success\n",
      "img_00633.jpg\n",
      "success\n",
      "img_00634.jpg\n",
      "success\n",
      "img_00636.jpg\n",
      "success\n",
      "img_00638.jpg\n",
      "success\n",
      "img_00643.jpg\n",
      "success\n",
      "img_00653.jpg\n",
      "success\n",
      "img_00660.jpg\n",
      "success\n",
      "img_00665.jpg\n",
      "success\n",
      "img_00668.jpg\n",
      "success\n",
      "img_00672.jpg\n",
      "success\n",
      "img_00679.jpg\n",
      "success\n",
      "img_00684.jpg\n",
      "success\n",
      "img_00687.jpg\n",
      "success\n",
      "img_00690.jpg\n",
      "success\n",
      "img_00701.jpg\n",
      "success\n",
      "img_00705.jpg\n",
      "success\n",
      "img_00706.jpg\n",
      "success\n",
      "img_00710.jpg\n",
      "success\n",
      "img_00712.jpg\n",
      "success\n",
      "img_00713.jpg\n",
      "success\n",
      "img_00714.jpg\n",
      "success\n",
      "img_00715.jpg\n",
      "success\n",
      "img_00719.jpg\n",
      "success\n",
      "img_00722.jpg\n",
      "success\n",
      "img_00727.jpg\n",
      "success\n",
      "img_00728.jpg\n",
      "success\n",
      "img_00741.jpg\n",
      "success\n",
      "img_00742.jpg\n",
      "success\n",
      "img_00744.jpg\n",
      "success\n",
      "img_00745.jpg\n",
      "success\n",
      "img_00747.jpg\n",
      "success\n",
      "img_00754.jpg\n",
      "success\n",
      "img_00756.jpg\n",
      "success\n",
      "img_00762.jpg\n",
      "success\n",
      "img_00782.jpg\n",
      "success\n",
      "img_00788.jpg\n",
      "success\n",
      "img_00790.jpg\n",
      "success\n",
      "img_00793.jpg\n",
      "success\n",
      "img_00809.jpg\n",
      "success\n",
      "img_00810.jpg\n",
      "success\n",
      "img_00811.jpg\n",
      "success\n",
      "img_00817.jpg\n",
      "success\n",
      "img_00820.jpg\n",
      "success\n",
      "img_00823.jpg\n",
      "success\n",
      "img_00824.jpg\n",
      "success\n",
      "img_00829.jpg\n",
      "success\n",
      "img_00831.jpg\n",
      "success\n",
      "img_00834.jpg\n",
      "success\n",
      "img_00840.jpg\n",
      "success\n",
      "img_00843.jpg\n",
      "success\n",
      "img_00863.jpg\n",
      "success\n",
      "img_00866.jpg\n",
      "success\n",
      "img_00869.jpg\n",
      "success\n",
      "img_00870.jpg\n",
      "success\n",
      "img_00878.jpg\n",
      "success\n",
      "img_00880.jpg\n",
      "success\n",
      "img_00881.jpg\n",
      "success\n",
      "img_00885.jpg\n",
      "success\n",
      "img_00893.jpg\n",
      "success\n",
      "img_00895.jpg\n",
      "success\n",
      "img_00897.jpg\n",
      "success\n",
      "img_00898.jpg\n",
      "success\n",
      "img_00899.jpg\n",
      "success\n",
      "img_00901.jpg\n",
      "success\n",
      "img_00911.jpg\n",
      "success\n",
      "img_00928.jpg\n",
      "success\n",
      "img_00939.jpg\n",
      "success\n",
      "img_00940.jpg\n",
      "success\n",
      "img_00956.jpg\n",
      "success\n",
      "img_00957.jpg\n",
      "success\n",
      "img_00961.jpg\n",
      "success\n",
      "img_00967.jpg\n",
      "success\n",
      "img_00970.jpg\n",
      "success\n",
      "img_00975.jpg\n",
      "success\n",
      "img_00984.jpg\n",
      "success\n",
      "img_00987.jpg\n",
      "success\n",
      "img_00993.jpg\n",
      "success\n",
      "img_00994.jpg\n",
      "success\n",
      "img_00996.jpg\n",
      "success\n",
      "img_00998.jpg\n",
      "success\n",
      "img_01000.jpg\n",
      "success\n",
      "img_01001.jpg\n",
      "success\n",
      "img_01006.jpg\n",
      "success\n",
      "img_01009.jpg\n",
      "success\n",
      "img_01011.jpg\n",
      "success\n",
      "img_01014.jpg\n",
      "success\n",
      "img_01021.jpg\n",
      "success\n",
      "img_01023.jpg\n",
      "success\n",
      "img_01025.jpg\n",
      "success\n",
      "img_01028.jpg\n",
      "success\n",
      "img_01029.jpg\n",
      "success\n",
      "img_01032.jpg\n",
      "success\n",
      "img_01033.jpg\n",
      "success\n",
      "img_01038.jpg\n",
      "success\n",
      "img_01045.jpg\n",
      "success\n",
      "img_01046.jpg\n",
      "success\n",
      "img_01047.jpg\n",
      "success\n",
      "img_01056.jpg\n",
      "success\n",
      "img_01063.jpg\n",
      "success\n",
      "img_01066.jpg\n",
      "success\n",
      "img_01070.jpg\n",
      "success\n",
      "img_01072.jpg\n",
      "success\n",
      "img_01074.jpg\n",
      "success\n",
      "img_01077.jpg\n",
      "success\n",
      "img_01079.jpg\n",
      "success\n",
      "img_01082.jpg\n",
      "success\n",
      "img_01083.jpg\n",
      "success\n",
      "img_01085.jpg\n",
      "success\n",
      "img_01086.jpg\n",
      "success\n",
      "img_01093.jpg\n",
      "success\n",
      "img_01095.jpg\n",
      "success\n",
      "img_01105.jpg\n",
      "success\n",
      "img_01109.jpg\n",
      "success\n",
      "img_01110.jpg\n",
      "success\n",
      "img_01111.jpg\n",
      "success\n",
      "img_01112.jpg\n",
      "success\n",
      "img_01117.jpg\n",
      "success\n",
      "img_01121.jpg\n",
      "success\n",
      "img_01125.jpg\n",
      "success\n",
      "img_01127.jpg\n",
      "success\n",
      "img_01128.jpg\n",
      "success\n",
      "img_01129.jpg\n",
      "success\n",
      "img_01130.jpg\n",
      "success\n",
      "img_01139.jpg\n",
      "success\n",
      "img_01141.jpg\n",
      "success\n",
      "img_01144.jpg\n",
      "success\n",
      "img_01152.jpg\n",
      "success\n",
      "img_01160.jpg\n",
      "success\n",
      "img_01162.jpg\n",
      "success\n",
      "img_01163.jpg\n",
      "success\n",
      "img_01183.jpg\n",
      "success\n",
      "img_01186.jpg\n",
      "success\n",
      "img_01191.jpg\n",
      "success\n",
      "img_01196.jpg\n",
      "success\n",
      "img_01197.jpg\n",
      "success\n",
      "img_01205.jpg\n",
      "success\n",
      "img_01206.jpg\n",
      "success\n",
      "img_01207.jpg\n",
      "success\n",
      "img_01225.jpg\n",
      "success\n",
      "img_01238.jpg\n",
      "success\n",
      "img_01239.jpg\n",
      "success\n",
      "img_01240.jpg\n",
      "success\n",
      "img_01243.jpg\n",
      "success\n",
      "img_01246.jpg\n",
      "success\n",
      "img_01247.jpg\n",
      "success\n",
      "img_01255.jpg\n",
      "success\n",
      "img_01261.jpg\n",
      "success\n",
      "img_01262.jpg\n",
      "success\n",
      "img_01265.jpg\n",
      "success\n",
      "img_01268.jpg\n",
      "success\n",
      "img_01271.jpg\n",
      "success\n",
      "img_01273.jpg\n",
      "success\n",
      "img_01276.jpg\n",
      "success\n",
      "img_01278.jpg\n",
      "success\n",
      "img_01282.jpg\n",
      "success\n",
      "img_01287.jpg\n",
      "success\n",
      "img_01291.jpg\n",
      "success\n",
      "img_01300.jpg\n",
      "success\n",
      "img_01304.jpg\n",
      "success\n",
      "img_01306.jpg\n",
      "success\n",
      "img_01313.jpg\n",
      "success\n",
      "img_01314.jpg\n",
      "success\n",
      "img_01316.jpg\n",
      "success\n",
      "img_01319.jpg\n",
      "success\n",
      "img_01330.jpg\n",
      "success\n",
      "img_01333.jpg\n",
      "success\n",
      "img_01334.jpg\n",
      "success\n",
      "img_01336.jpg\n",
      "success\n",
      "img_01338.jpg\n",
      "success\n",
      "img_01353.jpg\n",
      "success\n",
      "img_01354.jpg\n",
      "fail\n",
      "img_01355.jpg\n",
      "success\n",
      "img_01357.jpg\n",
      "success\n",
      "img_01361.jpg\n",
      "success\n",
      "img_01362.jpg\n",
      "success\n",
      "img_01363.jpg\n",
      "success\n",
      "img_01364.jpg\n",
      "success\n",
      "img_01367.jpg\n",
      "success\n",
      "img_01374.jpg\n",
      "success\n",
      "img_01390.jpg\n",
      "success\n",
      "img_01396.jpg\n",
      "success\n",
      "img_01398.jpg\n",
      "success\n",
      "img_01401.jpg\n",
      "success\n",
      "img_01402.jpg\n",
      "success\n",
      "img_01409.jpg\n",
      "success\n",
      "img_01416.jpg\n",
      "success\n",
      "img_01417.jpg\n",
      "success\n",
      "img_01422.jpg\n",
      "success\n",
      "img_01433.jpg\n",
      "success\n",
      "img_01434.jpg\n",
      "success\n",
      "img_01445.jpg\n",
      "fail\n",
      "img_01446.jpg\n",
      "success\n",
      "img_01448.jpg\n",
      "success\n",
      "img_01454.jpg\n",
      "success\n",
      "img_01455.jpg\n",
      "success\n",
      "img_01458.jpg\n",
      "success\n",
      "img_01460.jpg\n",
      "success\n",
      "img_01464.jpg\n",
      "success\n",
      "img_01466.jpg\n",
      "success\n",
      "img_01478.jpg\n",
      "success\n",
      "img_01480.jpg\n",
      "success\n",
      "img_01482.jpg\n",
      "success\n",
      "img_01485.jpg\n",
      "success\n",
      "img_01489.jpg\n",
      "success\n",
      "img_01506.jpg\n",
      "success\n",
      "img_01507.jpg\n",
      "success\n",
      "img_01509.jpg\n",
      "success\n",
      "img_01514.jpg\n",
      "success\n",
      "img_01520.jpg\n",
      "success\n",
      "img_01529.jpg\n",
      "success\n",
      "img_01540.jpg\n",
      "success\n",
      "img_01542.jpg\n",
      "success\n",
      "img_01547.jpg\n",
      "success\n",
      "img_01554.jpg\n",
      "success\n",
      "img_01556.jpg\n",
      "success\n",
      "img_01558.jpg\n",
      "success\n",
      "img_01570.jpg\n",
      "success\n",
      "img_01574.jpg\n",
      "success\n",
      "img_01578.jpg\n",
      "success\n",
      "img_01580.jpg\n",
      "success\n",
      "img_01584.jpg\n",
      "success\n",
      "img_01590.jpg\n",
      "success\n",
      "img_01599.jpg\n",
      "success\n",
      "img_01601.jpg\n",
      "success\n",
      "img_01603.jpg\n",
      "success\n",
      "img_01604.jpg\n",
      "success\n",
      "img_01607.jpg\n",
      "success\n",
      "img_01612.jpg\n",
      "success\n",
      "img_01620.jpg\n",
      "success\n",
      "img_01636.jpg\n",
      "success\n",
      "img_01638.jpg\n",
      "success\n",
      "img_01641.jpg\n",
      "success\n",
      "img_01645.jpg\n",
      "success\n",
      "img_01652.jpg\n",
      "success\n",
      "img_01654.jpg\n",
      "success\n",
      "img_01655.jpg\n",
      "success\n",
      "img_01660.jpg\n",
      "fail\n",
      "img_01663.jpg\n",
      "success\n",
      "img_01680.jpg\n",
      "success\n",
      "img_01682.jpg\n",
      "success\n",
      "img_01683.jpg\n",
      "success\n",
      "img_01686.jpg\n",
      "success\n",
      "img_01690.jpg\n",
      "success\n",
      "img_01693.jpg\n",
      "success\n",
      "img_01699.jpg\n",
      "success\n",
      "img_01713.jpg\n",
      "success\n",
      "img_01722.jpg\n",
      "success\n",
      "img_01728.jpg\n",
      "success\n",
      "img_01729.jpg\n",
      "success\n",
      "img_01733.jpg\n",
      "success\n",
      "img_01734.jpg\n",
      "success\n",
      "img_01735.jpg\n",
      "success\n",
      "img_01738.jpg\n",
      "success\n",
      "img_01741.jpg\n",
      "success\n",
      "img_01744.jpg\n",
      "success\n",
      "img_01753.jpg\n",
      "success\n",
      "img_01756.jpg\n",
      "success\n",
      "img_01763.jpg\n",
      "success\n",
      "img_01768.jpg\n",
      "success\n",
      "img_01772.jpg\n",
      "success\n",
      "img_01778.jpg\n",
      "success\n",
      "img_01786.jpg\n",
      "success\n",
      "img_01788.jpg\n",
      "success\n",
      "img_01790.jpg\n",
      "success\n",
      "img_01796.jpg\n",
      "success\n",
      "img_01797.jpg\n",
      "success\n",
      "img_01800.jpg\n",
      "success\n",
      "img_01804.jpg\n",
      "success\n",
      "img_01805.jpg\n",
      "success\n",
      "img_01806.jpg\n",
      "success\n",
      "img_01809.jpg\n",
      "success\n",
      "img_01810.jpg\n",
      "success\n",
      "img_01816.jpg\n",
      "success\n",
      "img_01819.jpg\n",
      "success\n",
      "img_01822.jpg\n",
      "success\n",
      "img_01823.jpg\n",
      "success\n",
      "img_01826.jpg\n",
      "success\n",
      "img_01830.jpg\n",
      "success\n",
      "img_01833.jpg\n",
      "success\n",
      "img_01838.jpg\n",
      "success\n",
      "img_01841.jpg\n",
      "success\n",
      "img_01846.jpg\n",
      "success\n",
      "img_01855.jpg\n",
      "success\n",
      "img_01858.jpg\n",
      "success\n",
      "img_01865.jpg\n",
      "success\n",
      "img_01869.jpg\n",
      "success\n",
      "img_01875.jpg\n",
      "success\n",
      "img_01878.jpg\n",
      "success\n",
      "img_01883.jpg\n",
      "success\n",
      "img_01884.jpg\n",
      "success\n",
      "img_01890.jpg\n",
      "success\n",
      "img_01896.jpg\n",
      "success\n",
      "img_01897.jpg\n",
      "success\n",
      "img_01901.jpg\n",
      "success\n",
      "img_01902.jpg\n",
      "success\n",
      "img_01909.jpg\n",
      "success\n",
      "img_01910.jpg\n",
      "success\n",
      "img_01911.jpg\n",
      "success\n",
      "img_01914.jpg\n",
      "success\n",
      "img_01917.jpg\n",
      "success\n",
      "img_01919.jpg\n",
      "success\n",
      "img_01921.jpg\n",
      "success\n",
      "img_01926.jpg\n",
      "success\n",
      "img_01928.jpg\n",
      "success\n",
      "img_01929.jpg\n",
      "success\n",
      "img_01931.jpg\n",
      "success\n",
      "img_01934.jpg\n",
      "success\n",
      "img_01936.jpg\n",
      "success\n",
      "img_01941.jpg\n",
      "success\n",
      "img_01948.jpg\n",
      "success\n",
      "img_01949.jpg\n",
      "success\n",
      "img_01950.jpg\n",
      "success\n",
      "img_01954.jpg\n",
      "success\n",
      "img_01958.jpg\n",
      "success\n",
      "img_01975.jpg\n",
      "success\n",
      "img_01980.jpg\n",
      "success\n",
      "img_01985.jpg\n",
      "success\n",
      "img_01990.jpg\n",
      "success\n",
      "img_01992.jpg\n",
      "success\n",
      "img_02002.jpg\n",
      "success\n",
      "img_02005.jpg\n",
      "success\n",
      "img_02008.jpg\n",
      "success\n",
      "img_02012.jpg\n",
      "success\n",
      "img_02018.jpg\n",
      "success\n",
      "img_02019.jpg\n",
      "success\n",
      "img_02025.jpg\n",
      "success\n",
      "img_02030.jpg\n",
      "success\n",
      "img_02032.jpg\n",
      "success\n",
      "img_02034.jpg\n",
      "success\n",
      "img_02035.jpg\n",
      "success\n",
      "img_02036.jpg\n",
      "success\n",
      "img_02039.jpg\n",
      "success\n",
      "img_02046.jpg\n",
      "success\n",
      "img_02047.jpg\n",
      "success\n",
      "img_02052.jpg\n",
      "success\n",
      "img_02058.jpg\n",
      "success\n",
      "img_02063.jpg\n",
      "success\n",
      "img_02068.jpg\n",
      "success\n",
      "img_02069.jpg\n",
      "success\n",
      "img_02072.jpg\n",
      "success\n",
      "img_02086.jpg\n",
      "success\n",
      "img_02090.jpg\n",
      "success\n",
      "img_02106.jpg\n",
      "success\n",
      "img_02107.jpg\n",
      "success\n",
      "img_02108.jpg\n",
      "success\n",
      "img_02109.jpg\n",
      "success\n",
      "img_02112.jpg\n",
      "success\n",
      "img_02118.jpg\n",
      "success\n",
      "img_02120.jpg\n",
      "success\n",
      "img_02133.jpg\n",
      "success\n",
      "img_02134.jpg\n",
      "success\n",
      "img_02140.jpg\n",
      "success\n",
      "img_02148.jpg\n",
      "success\n",
      "img_02151.jpg\n",
      "success\n",
      "img_02163.jpg\n",
      "success\n",
      "img_02170.jpg\n",
      "success\n",
      "img_02171.jpg\n",
      "success\n",
      "img_02174.jpg\n",
      "success\n",
      "img_02178.jpg\n",
      "success\n",
      "img_02182.jpg\n",
      "success\n",
      "img_02184.jpg\n",
      "success\n",
      "img_02185.jpg\n",
      "success\n",
      "img_02189.jpg\n",
      "success\n",
      "img_02190.jpg\n",
      "success\n",
      "img_02192.jpg\n",
      "success\n",
      "img_02197.jpg\n",
      "success\n",
      "img_02201.jpg\n",
      "success\n",
      "img_02203.jpg\n",
      "success\n",
      "img_02205.jpg\n",
      "success\n",
      "img_02208.jpg\n",
      "success\n",
      "img_02227.jpg\n",
      "success\n",
      "img_02229.jpg\n",
      "success\n",
      "img_02250.jpg\n",
      "success\n",
      "img_02253.jpg\n",
      "success\n",
      "img_02254.jpg\n",
      "success\n",
      "img_02263.jpg\n",
      "success\n",
      "img_02273.jpg\n",
      "success\n",
      "img_02276.jpg\n",
      "success\n",
      "img_02283.jpg\n",
      "success\n",
      "img_02286.jpg\n",
      "success\n",
      "img_02289.jpg\n",
      "success\n",
      "img_02292.jpg\n",
      "success\n",
      "img_02296.jpg\n",
      "success\n",
      "img_02324.jpg\n",
      "success\n",
      "img_02326.jpg\n",
      "success\n",
      "img_02328.jpg\n",
      "success\n",
      "img_02338.jpg\n",
      "success\n",
      "img_02340.jpg\n",
      "success\n",
      "img_02342.jpg\n",
      "success\n",
      "img_02346.jpg\n",
      "success\n",
      "img_02352.jpg\n",
      "success\n",
      "img_02359.jpg\n",
      "success\n",
      "img_02361.jpg\n",
      "success\n",
      "img_02362.jpg\n",
      "success\n",
      "img_02373.jpg\n",
      "success\n",
      "img_02376.jpg\n",
      "success\n",
      "img_02382.jpg\n",
      "success\n",
      "img_02386.jpg\n",
      "success\n",
      "img_02388.jpg\n",
      "success\n",
      "img_02392.jpg\n",
      "success\n",
      "img_02393.jpg\n",
      "success\n",
      "img_02396.jpg\n",
      "success\n",
      "img_02399.jpg\n",
      "success\n",
      "img_02404.jpg\n",
      "success\n",
      "img_02405.jpg\n",
      "success\n",
      "img_02408.jpg\n",
      "success\n",
      "img_02410.jpg\n",
      "success\n",
      "img_02414.jpg\n",
      "success\n",
      "img_02418.jpg\n",
      "success\n",
      "img_02420.jpg\n",
      "success\n",
      "img_02421.jpg\n",
      "success\n",
      "img_02425.jpg\n",
      "success\n",
      "img_02433.jpg\n",
      "success\n",
      "img_02436.jpg\n",
      "success\n",
      "img_02437.jpg\n",
      "success\n",
      "img_02446.jpg\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "import pickle\n",
    "\n",
    "if os.path.exists('../data/data_train_annotation_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist data_train_annotation_{}_{}.pickle. Loading data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/data_train_annotation_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        data_train = pickle.load(f)\n",
    "    X_train = data_train['X_train']\n",
    "    y_train = data_train['y_train']\n",
    "    del data_train\n",
    "else:\n",
    "    print ('Loading data from original images. Generating data_train_annotation_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "    \n",
    "    images = []\n",
    "    y_train = []\n",
    "\n",
    "    crop_classes=FISH_CLASSES[:]\n",
    "    crop_classes.remove('NoF')\n",
    "    crop_classes\n",
    "\n",
    "    for c in crop_classes:\n",
    "        labels = pd.read_json('../data/annotation/'+c.lower()+'_labels.json')\n",
    "        for i in range(len(labels)):\n",
    "            try:\n",
    "                img_filename = labels.iloc[i,2]\n",
    "                print(img_filename)\n",
    "                l1 = pd.DataFrame((labels[labels.filename==img_filename].annotations).iloc[0])\n",
    "                image = imread(TRAIN_DIR+c+'/'+img_filename)\n",
    "                rescale = 1./255,\n",
    "                image = image*rescale\n",
    "                images.append(image)\n",
    "                y_train.append([l1.iloc[0,1],l1.iloc[0,2],l1.iloc[1,1],l1.iloc[1,2]])\n",
    "                print('success')\n",
    "            except:\n",
    "                print('fail')\n",
    "\n",
    "    X_train = np.asarray(images, dtype=np.float32)\n",
    "\n",
    "    # One Hot Encoding Labels\n",
    "    y_train = le.transform(y_train)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "    #save data to file\n",
    "    data_train = {'X_train': X_train,'y_train': y_train }\n",
    "\n",
    "    with open('../data/data_train_annotation_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(data_train, f)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=None, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "#train_datagen.fit(X_train)\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BatchSize, shuffle=True, seed=None)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = valid_datagen.flow(X_valid, y_valid, batch_size=BatchSize, shuffle=True, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='./checkpoints/weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "        \n",
    "learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stg1 training\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(FISH_CLASSES), init='glorot_normal', activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "hist = model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=300, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stg2 training\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:14]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[14:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "hist = model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=300, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resume training\n",
    "\n",
    "files = glob.glob('./checkpoints/*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "\n",
    "hist = model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=300, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test submission\n",
    "\n",
    "import datetime\n",
    "\n",
    "if os.path.exists('../data/data_test_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist data_test_{}_{}.pickle. Loading test data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/data_test_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        data_test = pickle.load(f)\n",
    "    X_test = data_test['X_test']\n",
    "    test_files = data_test['test_files']\n",
    "else:\n",
    "    print ('Loading test data from original images. Generating data_test_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "\n",
    "    test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "    X_test = np.ndarray((len(test_files), ROWS, COLS, 3), dtype=np.uint8)\n",
    "\n",
    "    for i, im in enumerate(test_files): \n",
    "        X_test[i] = read_image(TEST_DIR+im)\n",
    "        if i%300 == 0: print('Processed {} of {}'.format(i, len(test_files)))\n",
    "            \n",
    "    data_test = {'X_test': X_test,'test_files': test_files }\n",
    "    \n",
    "    with open('../data/data_test_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(data_test, f)\n",
    "            \n",
    "X_test = X_test / 255.\n",
    "\n",
    "files = glob.glob('./checkpoints/*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "model = load_model(files[index])\n",
    "\n",
    "test_preds = model.predict(X_test, batch_size=BatchSize, verbose=1)\n",
    "#test_preds= test_preds / np.sum(test_preds,axis=1,keepdims=True)\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "#submission.loc[:, 'image'] = pd.Series(test_files, index=submission.index)\n",
    "submission.insert(0, 'image', test_files)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "info = modelStr + '{:.4f}'.format(min(val_losses))\n",
    "sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###clear checkpoints folder\n",
    "\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.mkdir('./checkpoints')\n",
    "files = glob.glob('./checkpoints/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###clear logs folder\n",
    "\n",
    "if not os.path.exists('./logs'):\n",
    "    os.mkdir('./logs')\n",
    "files = glob.glob('./logs/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
