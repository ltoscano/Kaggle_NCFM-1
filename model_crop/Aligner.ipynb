{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, random, glob, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "K.set_floatx(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "TEST_DIR = '../data/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "modelStr = 'Crop'\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 64\n",
    "LearningRate = 1e-4\n",
    "le = LabelEncoder()\n",
    "le.fit(FISH_CLASSES)\n",
    "le.transform(FISH_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exist images_annotations_224_224.pickle. Loading data from file.\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "import pickle\n",
    "\n",
    "if os.path.exists('../data/images_annotations_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist images_annotations_{}_{}.pickle. Loading data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/images_annotations_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        images_annotations = pickle.load(f)\n",
    "    images = images_annotations['images']\n",
    "    annotations = images_annotations['annotations']\n",
    "else:\n",
    "    print ('Loading data from original images. Generating images_annotations_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "    \n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    crop_classes=FISH_CLASSES[:]\n",
    "    crop_classes.remove('NoF')\n",
    "    crop_classes\n",
    "\n",
    "    for c in crop_classes:\n",
    "        labels = pd.read_json('../data/annotation/'+c.lower()+'_labels.json')\n",
    "        for i in range(len(labels)):\n",
    "            try:\n",
    "                img_filename = labels.iloc[i,2]\n",
    "                print(img_filename)\n",
    "                l1 = pd.DataFrame((labels[labels.filename==img_filename].annotations).iloc[0])\n",
    "                im = Image.open(TRAIN_DIR+c+'/'+img_filename)\n",
    "                im_resized = im.resize((COLS, ROWS), Image.BILINEAR)\n",
    "                w, h = im.size\n",
    "                x_ratio = float(COLS)/w\n",
    "                y_ratio = float(ROWS)/h\n",
    "                annotations.append([l1.iloc[0,1]*x_ratio,\n",
    "                                    l1.iloc[0,2]*y_ratio,\n",
    "                                    l1.iloc[1,1]*x_ratio,\n",
    "                                    l1.iloc[1,2]*y_ratio])\n",
    "                images.append(np.asarray(im_resized))\n",
    "                print('success')\n",
    "            except:\n",
    "                print('fail')\n",
    "    \n",
    "    images = np.asarray(images, dtype=np.uint8)\n",
    "    annotations = np.asarray(annotations)\n",
    "    #save data to file\n",
    "    images_annotations = {'images': images,'annotations': annotations }\n",
    "\n",
    "    with open('../data/images_annotations_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(images_annotations, f)\n",
    "        \n",
    "images_train, images_valid, annotations_train, annotations_valid = train_test_split(images, annotations, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成图像随机变换矩阵\n",
    "#modified from code https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py\n",
    "\n",
    "def transform_matrix_offset_center(matrix, w, h):\n",
    "    center_x = float(w) / 2 + 0.5\n",
    "    center_y = float(h) / 2 + 0.5\n",
    "    #图像center移到原点，进行rotation和shear\n",
    "    offset_matrix = np.array([[1, 0, center_x], [0, 1, center_y], [0, 0, 1]])\n",
    "    #移回来\n",
    "    reset_matrix = np.array([[1, 0, -center_x], [0, 1, -center_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(reset_matrix, matrix), offset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def random_transform_matrix(image,\n",
    "                            rotation_range=0.,\n",
    "                            width_shift_range=0.,\n",
    "                            height_shift_range=0.,\n",
    "                            shear_range=0.,\n",
    "                            zoom_range=0.,\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False):\n",
    "    \n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "       \n",
    "    #图像上下翻转\n",
    "    hflip_matrix=np.eye(3)\n",
    "    if horizontal_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            #print(\"horizontal_flip\")\n",
    "            hflip_matrix = np.array([[-1, 0, w],\n",
    "                                     [0, 1, 0],\n",
    "                                     [0, 0, 1]])\n",
    "    #图像左右翻转                              \n",
    "    vflip_matrix=np.eye(3)\n",
    "    if vertical_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            #print(\"vertical_flip\")\n",
    "            vflip_matrix = np.array([[1, 0, 0],\n",
    "                                     [0, -1, h],\n",
    "                                     [0, 0, 1]])\n",
    "    #图像顺时针旋转theta       \n",
    "    if rotation_range:\n",
    "        theta = np.pi / 180 * np.random.uniform(-rotation_range, rotation_range)\n",
    "    else:\n",
    "        theta = 0\n",
    "    #print(\"theta =\",theta)\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    \n",
    "    #图像往正轴移动tx，ty\n",
    "    if height_shift_range:\n",
    "        ty = np.random.uniform(-height_shift_range, height_shift_range) * h\n",
    "    else:\n",
    "        ty = 0\n",
    "\n",
    "    if width_shift_range:\n",
    "        tx = np.random.uniform(-width_shift_range, width_shift_range) * w\n",
    "    else:\n",
    "        tx = 0\n",
    "    #print(\"tx =\",tx)\n",
    "    #print(\"ty =\",ty)\n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty],\n",
    "                                   [0, 0, 1]])\n",
    "    \n",
    "    #图像顺时针shear\n",
    "    if shear_range:\n",
    "        shear = np.random.uniform(-shear_range, shear_range)\n",
    "    else:\n",
    "        shear = 0\n",
    "    #print(\"shear =\",shear)\n",
    "    shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                             [0, np.cos(shear), 0],\n",
    "                             [0, 0, 1]])\n",
    "    \n",
    "    #以center为中心图像放大zx，zy\n",
    "    if np.isscalar(zoom_range):\n",
    "        zoom_range = [1 - zoom_range, 1 + zoom_range]\n",
    "    elif len(zoom_range) == 2:\n",
    "        zoom_range = [zoom_range[0], zoom_range[1]]\n",
    "    else:\n",
    "        raise ValueError('zoom_range should be a float or '\n",
    "                         'a tuple or list of two floats. '\n",
    "                         'Received arg: ', zoom_range)\n",
    "            \n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    #print(\"zx =\",zx)\n",
    "    #print(\"zy =\",zy)\n",
    "    zoom_matrix = np.array([[zx, 0, (1-zx)*w/2.],\n",
    "                            [0, zy, (1-zy)*h/2.],\n",
    "                            [0, 0, 1]])\n",
    "    #transform_matrix = zoom_matrix\n",
    "    transform_matrix = np.dot(shear_matrix, rotation_matrix)\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, w, h)\n",
    "    transform_matrix = np.dot(np.dot(np.dot(np.dot(translation_matrix, \n",
    "                                                   zoom_matrix), \n",
    "                                            transform_matrix), \n",
    "                                     vflip_matrix), \n",
    "                              hflip_matrix)\n",
    "    return transform_matrix[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_nb_batch = 20\n",
    "\n",
    "\n",
    "def model_train(model, images_train, annotations_train, images_valid, annotations_valid, nb_batch = 1000):\n",
    "    import queue\n",
    "    q_images = queue.Queue()\n",
    "    q_annotations = queue.Queue()\n",
    "    \n",
    "    min_val_loss = float(\"Inf\")\n",
    "    for i in range(nb_batch):\n",
    "        count = 0\n",
    "        x_batch = np.ndarray((BatchSize, ROWS, COLS, 3), dtype=np.float32)\n",
    "        y_batch = np.ndarray((BatchSize, 4), dtype=np.float32)\n",
    "        \n",
    "        while count<BatchSize:\n",
    "            if q_images.empty():\n",
    "\n",
    "                #shuffle epoch\n",
    "                epoch_size = len(images_train)\n",
    "                index = np.random.permutation(epoch_size)\n",
    "                images_train = images_train[index,:,:,:]\n",
    "                annotations_train = annotations_train[index,:]\n",
    "\n",
    "                for i in range(epoch_size):\n",
    "                    q_images.put(images_train[i])\n",
    "                    q_annotations.put(annotations_train[i])\n",
    "            else:\n",
    "                image = q_images.get()\n",
    "                annotation = q_annotations.get()\n",
    "                rescale = 1./255,\n",
    "                image = image*rescale\n",
    "                M = random_transform_matrix(image,\n",
    "                                            rotation_range=20,\n",
    "                                            shear_range=0.2,\n",
    "                                            zoom_range=0.1,\n",
    "                                            width_shift_range=0.1,\n",
    "                                            height_shift_range=0.1,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True)\n",
    "                h, w = image.shape[0], image.shape[1]\n",
    "                image_transformed = cv2.warpAffine(image, M, (w, h), borderMode=0)\n",
    "                head_transformed = np.dot(M,np.array([annotation[0],annotation[1],1]))\n",
    "                tail_transformed = np.dot(M,np.array([annotation[2],annotation[3],1]))\n",
    "                if 0<=head_transformed[0]<=w and 0<=head_transformed[1]<=h and \\\n",
    "                0<=tail_transformed[0]<=w and 0<=tail_transformed[1]<=h:\n",
    "                    x_batch[count] = image_transformed\n",
    "                    y_batch[count] = [head_transformed[0],head_transformed[1],tail_transformed[0],tail_transformed[1]]\n",
    "                    count += 1\n",
    "\n",
    "        train_losses.append(model.train_on_batch(x_batch, y_batch))       \n",
    "        if i % val_nb_batch == 0:\n",
    "            print('Batch ', i)\n",
    "            val_losses.append(model.evaluate(images_valid, annotations_valid, batch_size=BatchSize, verbose=1))  \n",
    "            print('train_loss', train_losses[-1], 'val_losses', val_losses[-1])\n",
    "            if val_losses[-1] < min_val_loss:\n",
    "                min_val_loss = val_losses[-1]\n",
    "                model.save('./checkpoints/model-{:.4f}.h5'.format(val_losses[-1]))\n",
    "                print('Saving model-{:.4f}.h5'.format(val_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  20\n",
      "660/660 [==============================] - 20s    \n",
      "train_loss 14345.8 val_losses 11964.0433475\n",
      "Saving model-11964.0433.h5\n",
      "Batch  40\n",
      "660/660 [==============================] - 10s    \n",
      "train_loss 13572.9 val_losses 10041.8991951\n",
      "Saving model-10041.8992.h5\n"
     ]
    }
   ],
   "source": [
    "#stg1 training\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, init='glorot_normal')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model_train(model, images_train, annotations_train, images_valid, annotations_valid, nb_batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stg2 training\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:14]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[14:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "\n",
    "model_train(model, images_train, annotations_train, images_valid, annotations_valid, nb_batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resume training\n",
    "\n",
    "files = glob.glob('./checkpoints/*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "\n",
    "model_train(model, images_train, annotations_train, images_valid, annotations_valid, nb_batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses); plt.plot([val_nb_batch*i for i in range(len(val_losses))], val_losses); \n",
    "plt.title('model loss'); plt.ylabel('mse'); plt.xlabel('batch');\n",
    "plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test submission\n",
    "\n",
    "import datetime\n",
    "\n",
    "if os.path.exists('../data/data_test_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist data_test_{}_{}.pickle. Loading test data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/data_test_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        data_test = pickle.load(f)\n",
    "    X_test = data_test['X_test']\n",
    "    test_files = data_test['test_files']\n",
    "else:\n",
    "    print ('Loading test data from original images. Generating data_test_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "\n",
    "    test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "    X_test = np.ndarray((len(test_files), ROWS, COLS, 3), dtype=np.uint8)\n",
    "\n",
    "    for i, im in enumerate(test_files): \n",
    "        X_test[i] = read_image(TEST_DIR+im)\n",
    "        if i%300 == 0: print('Processed {} of {}'.format(i, len(test_files)))\n",
    "            \n",
    "    data_test = {'X_test': X_test,'test_files': test_files }\n",
    "    \n",
    "    with open('../data/data_test_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(data_test, f)\n",
    "            \n",
    "X_test = X_test / 255.\n",
    "\n",
    "files = glob.glob('./checkpoints/*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "model = load_model(files[index])\n",
    "\n",
    "test_preds = model.predict(X_test, batch_size=BatchSize, verbose=1)\n",
    "#test_preds= test_preds / np.sum(test_preds,axis=1,keepdims=True)\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "#submission.loc[:, 'image'] = pd.Series(test_files, index=submission.index)\n",
    "submission.insert(0, 'image', test_files)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "info = modelStr + '{:.4f}'.format(min(val_losses))\n",
    "sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###clear checkpoints folder\n",
    "\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.mkdir('./checkpoints')\n",
    "files = glob.glob('./checkpoints/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###clear logs folder\n",
    "\n",
    "if not os.path.exists('./logs'):\n",
    "    os.mkdir('./logs')\n",
    "files = glob.glob('./logs/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
