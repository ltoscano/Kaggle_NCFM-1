{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17a737e2-ff67-6170-1229-bb95dbb2f65a"
   },
   "source": [
    "# Start-to-Finish Solution in Keras\n",
    "\n",
    "Here is my basic method for getting a LB submission churned out. No parameter tuning or data augmentation has been attempted, which should increase the score significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e6a4aad9-f09f-8f20-a9d0-159f5ef6c922",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "TRAIN_DIR = '../input/train/'\n",
    "TEST_DIR = '../input/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "ROWS = 90  #720\n",
    "COLS = 160 #1280\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dec4ed7b-f0b8-0c30-5431-3bd652c190da"
   },
   "source": [
    "# Loading and Preprocessing Data\n",
    "\n",
    "Not much processing, other than resizing to 90x160, but you will probably want to run larger images on a GPU for a higher score. I am also keeping track of the labels as I loop through each image folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d8f4e77d-ce91-48f7-c04a-ba225f893f0c",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 photos of ALB\n",
      "200 photos of BET\n",
      "117 photos of DOL\n",
      "67 photos of LAG\n",
      "465 photos of NoF\n",
      "299 photos of OTHER\n",
      "176 photos of SHARK\n",
      "734 photos of YFT\n"
     ]
    }
   ],
   "source": [
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "\n",
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "7547d288-1ca9-c45e-0efb-75ea832cb318",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777\n",
      "(3777, 90, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "18a6f374-8c0e-b332-3e46-46a732b96930",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uncomment to check out a fish from each class\n",
    "#uniq = np.unique(y_all, return_index=True)\n",
    "# for f, i in zip(uniq[0], uniq[1]):\n",
    "    #plt.imshow(X_all[i])\n",
    "    #plt.title(f)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25a3b3b2-a00e-d618-9d2c-4dc18ad14744"
   },
   "source": [
    "# Splitting the Training Data\n",
    "\n",
    "One-Hot-Encode the labels, then create a stratified train/validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "0537e039-ae27-ea4e-82a6-23603d9aa007",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = np_utils.to_categorical(y_all)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2256352-79ff-78eb-24d8-f1874d32cbf4"
   },
   "source": [
    "## The Model\n",
    "\n",
    "Pretty typical CNN in Keras with a plenty of dropout regularization between the fully connected layers. Note: I set the epochs to 1 to avoid timing out - change it to around 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "6e2396d3-d295-9616-d327-99cbe76b8851",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'categorical_crossentropy'\n",
    "\n",
    "def center_normalize(x):\n",
    "    return (x - K.mean(x)) / K.std(x)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(FISH_CLASSES)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "461ff410-5bca-f26d-5b4b-722fb2681e33",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2416 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 751s - loss: 1.8460 - val_loss: 1.6922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe17834ddd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "        \n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n",
    "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6c3c125c-e273-99a5-8360-8b717b9b9e58",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 68s    \n",
      "Validation Log Loss: 1.6538071293364127\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid, verbose=1)\n",
    "print(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6020ea37-c78f-a6f3-0877-2196833f8790"
   },
   "source": [
    "# Predicting the Test Set\n",
    "\n",
    "Finishing off with predictions on the test set. Scored LB 1.279 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c4769ce7-367c-5240-b615-714972d8e596",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 91s    \n"
     ]
    }
   ],
   "source": [
    "test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(TEST_DIR+im)\n",
    "    \n",
    "test_preds = model.predict(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "dfe3630b-9944-e91e-102d-d26efdcaa90f",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_07659.jpg</td>\n",
       "      <td>0.934675</td>\n",
       "      <td>0.303160</td>\n",
       "      <td>0.197579</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.448820</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.214206</td>\n",
       "      <td>0.764785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_06137.jpg</td>\n",
       "      <td>0.971155</td>\n",
       "      <td>0.251610</td>\n",
       "      <td>0.139805</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.436996</td>\n",
       "      <td>0.203325</td>\n",
       "      <td>0.146811</td>\n",
       "      <td>0.828368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_04962.jpg</td>\n",
       "      <td>0.978250</td>\n",
       "      <td>0.234622</td>\n",
       "      <td>0.120625</td>\n",
       "      <td>0.041260</td>\n",
       "      <td>0.434622</td>\n",
       "      <td>0.189285</td>\n",
       "      <td>0.131255</td>\n",
       "      <td>0.842724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03587.jpg</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>0.308464</td>\n",
       "      <td>0.202211</td>\n",
       "      <td>0.102841</td>\n",
       "      <td>0.450625</td>\n",
       "      <td>0.267345</td>\n",
       "      <td>0.217775</td>\n",
       "      <td>0.758838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_03715.jpg</td>\n",
       "      <td>0.928996</td>\n",
       "      <td>0.314201</td>\n",
       "      <td>0.210639</td>\n",
       "      <td>0.109750</td>\n",
       "      <td>0.462406</td>\n",
       "      <td>0.280586</td>\n",
       "      <td>0.207606</td>\n",
       "      <td>0.755778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_07659.jpg  0.934675  0.303160  0.197579  0.098237  0.448820  0.261274   \n",
       "1  img_06137.jpg  0.971155  0.251610  0.139805  0.051158  0.436996  0.203325   \n",
       "2  img_04962.jpg  0.978250  0.234622  0.120625  0.041260  0.434622  0.189285   \n",
       "3  img_03587.jpg  0.930818  0.308464  0.202211  0.102841  0.450625  0.267345   \n",
       "4  img_03715.jpg  0.928996  0.314201  0.210639  0.109750  0.462406  0.280586   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.214206  0.764785  \n",
       "1  0.146811  0.828368  \n",
       "2  0.131255  0.842724  \n",
       "3  0.217775  0.758838  \n",
       "4  0.207606  0.755778  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 9,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
