{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, random, glob, pickle, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from skimage.data import imread\n",
    "from skimage.io import imshow,imsave\n",
    "import cv2\n",
    "from skimage.util import crop\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "TEST_DIR = '../RFCN/JPEGImages/'\n",
    "TRAIN_CROP_DIR = '../data/train_crop/'\n",
    "TEST_CROP_DIR = '../data/test_stg1_crop/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "CONF_THRESH = 0.8\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 128\n",
    "LearningRate = 1e-4\n",
    "le = LabelEncoder()\n",
    "le.fit(FISH_CLASSES)\n",
    "le.transform(FISH_CLASSES)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#crop and cache to TRAIN_CROP_DIR by BBannotations\n",
    "if not os.path.exists(TRAIN_CROP_DIR):\n",
    "    os.mkdir(TRAIN_CROP_DIR)\n",
    "\n",
    "for c in FISH_CLASSES:\n",
    "    TRAIN_CROP_DIR_c = TRAIN_CROP_DIR + '{}/'.format(c)\n",
    "    if not os.path.exists(TRAIN_CROP_DIR_c):\n",
    "        os.mkdir(TRAIN_CROP_DIR_c)\n",
    "    files = glob.glob(TRAIN_CROP_DIR_c+'*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "crop_classes=FISH_CLASSES[:]\n",
    "crop_classes.remove('NoF')\n",
    "count = {}\n",
    "\n",
    "for c in crop_classes:\n",
    "    j = json.load(open('../data/BBannotations/{}.json'.format(c), 'r'))\n",
    "    for l in j: \n",
    "        filename = l[\"filename\"]\n",
    "        head, tail = os.path.split(filename)\n",
    "        basename, file_extension = os.path.splitext(tail) \n",
    "        image = Image.open(TRAIN_DIR+c+'/'+tail)\n",
    "        for i in range(len(l[\"annotations\"])):\n",
    "            a = l[\"annotations\"][i]\n",
    "            file_crop = TRAIN_CROP_DIR + '{}/'.format(a[\"class\"])+c+'_'+basename+'_{}_'.format(i)+a[\"class\"]+'.jpg'\n",
    "            xmin = (a[\"x\"])\n",
    "            ymin = (a[\"y\"])\n",
    "            width = (a[\"width\"])\n",
    "            height = (a[\"height\"])\n",
    "            xmax = xmin + width\n",
    "            ymax = ymin + height\n",
    "            #save cropped img\n",
    "            cropped = image.crop((max(xmin,0), max(ymin,0), xmax, ymax))\n",
    "            #cropped = image[max(ymin,0):ymax, max(xmin,0):xmax]\n",
    "            width_cropped, height_cropped = cropped.size\n",
    "            if height_cropped > width_cropped: cropped = cropped.transpose(method=2)\n",
    "            cropped.save(file_crop)\n",
    "            if a[\"class\"] != c: print(file_crop)\n",
    "    count[c] = len(os.listdir(TRAIN_CROP_DIR+c))\n",
    "\n",
    "num_NoF = sum(count.values())*3\n",
    "\n",
    "#crop and cache to TRAIN_CROP_DIR/NoF by RFCN\n",
    "#crop images by detections_full_AGNOSTICnms.pkl\n",
    "\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "\n",
    "train_detections_full_AGNOSTICnms = detections_full_AGNOSTICnms[1000:]\n",
    "num_NoF_perIm = math.ceil(num_NoF / len(train_detections_full_AGNOSTICnms))\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for im in range(len(train_detections_full_AGNOSTICnms)):\n",
    "#for im in range(1):\n",
    "    outputs_im = []\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if np.max(detects_im[i,5:]) <= CONF_THRESH and detects_im[i,4] >= CONF_THRESH:\n",
    "            outputs_im.append(detects_im[i,:]) \n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    inds = np.argsort(np.max(outputs_im[:,5:], axis=1))\n",
    "    outputs_im = outputs_im[inds,:]\n",
    "    outputs.append(outputs_im[:num_NoF_perIm, :])\n",
    "\n",
    "train_outputs = outputs\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "train_files = [im[:-1]+'.jpg' for im in ims][1000:]\n",
    "\n",
    "for i in range(len(train_outputs)):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    filename = train_files[i]\n",
    "    bboxes = train_outputs[i]\n",
    "    basename, file_extension = os.path.splitext(filename) \n",
    "    image = Image.open(TEST_DIR+filename)\n",
    "    for j in range(len(bboxes)):\n",
    "        bbox = bboxes[j]\n",
    "        xmin = bbox[0]\n",
    "        ymin = bbox[1]\n",
    "        xmax = bbox[2]\n",
    "        ymax = bbox[3]\n",
    "        file_crop = TRAIN_CROP_DIR+'NoF/'+basename+'_{}_'.format(j)+'.jpg'\n",
    "        cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "        width_cropped, height_cropped = cropped.size\n",
    "        if height_cropped > width_cropped: cropped = cropped.transpose(method=2)\n",
    "        cropped.save(file_crop)  \n",
    "\n",
    "count['NoF'] = len(os.listdir(TRAIN_CROP_DIR+'NoF'))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#visualize test image crop\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "train_files = [im[:-1]+'.jpg' for im in ims][1000:]\n",
    "\n",
    "for j in range(10):\n",
    "    dets = train_outputs[j]\n",
    "    print(dets)\n",
    "    im = Image.open(\"../RFCN/JPEGImages/\"+train_files[j])\n",
    "    im = np.asarray(im)\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in range(dets.shape[0]):\n",
    "        bbox = dets[i, :4]\n",
    "        score = np.amax(dets[i,4:])\n",
    "        index = np.argmax(dets[i,4:])\n",
    "        class_name = FISH_CLASSES[index]\n",
    "        #if not (bbox[0] == 0 and bbox[1] == 0 and bbox[2] == 0 and bbox[3] == 0):\n",
    "        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5))\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('Image {} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(j, class_name, CONF_THRESH),fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "im = Image.open('../data/train_crop/ALB/SHARK_img_06082_2_ALB.jpg')\n",
    "imshow(np.asarray(im))\n",
    "\n",
    "im_sizes = []\n",
    "for c in crop_classes:\n",
    "    TRAIN_CROP_DIR_c = TRAIN_CROP_DIR + '{}/'.format(c)\n",
    "    files = glob.glob(TRAIN_CROP_DIR_c+'*')\n",
    "    for file in files:\n",
    "        im = Image.open(file)\n",
    "        #size = (width, height)\n",
    "        size = im.size\n",
    "        im_sizes.append(size)\n",
    "im_sizes = np.asarray(im_sizes)\n",
    "\n",
    "len(im_sizes)\n",
    "\n",
    "np.mean(im_sizes[:,1]/im_sizes[:,0])\n",
    "\n",
    "plt.hist(im_sizes[:,1]/im_sizes[:,0], bins=10)\n",
    "\n",
    "plt.scatter(im_sizes[:,0],im_sizes[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exist data_train_BBCrop_224_224.pickle. Loading data from file.\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "import pickle\n",
    "\n",
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_CROP_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = Image.open(src)\n",
    "    im = im.resize((COLS, ROWS), Image.BILINEAR)\n",
    "    im = np.asarray(im)\n",
    "    return im\n",
    "\n",
    "if os.path.exists('../data/data_train_BBCrop_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist data_train_BBCrop_{}_{}.pickle. Loading data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/data_train_BBCrop_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        data_train = pickle.load(f)\n",
    "    X_train = data_train['X_train']\n",
    "    y_train = data_train['y_train']\n",
    "else:\n",
    "    print ('Loading data from original images. Generating data_train_BBCrop_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "    \n",
    "    files = []\n",
    "    y_train = []\n",
    "\n",
    "    for fish in FISH_CLASSES:\n",
    "        fish_files = get_images(fish)\n",
    "        files.extend(fish_files)\n",
    "\n",
    "        y_fish = np.tile(fish, len(fish_files))\n",
    "        y_train.extend(y_fish)\n",
    "        #print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    X_train = np.ndarray((len(files), ROWS, COLS, 3), dtype=np.uint8)\n",
    "\n",
    "    for i, im in enumerate(files): \n",
    "        X_train[i] = read_image(TRAIN_CROP_DIR+im)\n",
    "        if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "    #X_train = X_train / 255.\n",
    "    #print(X_train.shape)\n",
    "\n",
    "    # One Hot Encoding Labels\n",
    "    y_train = le.transform(y_train)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    \n",
    "    #save data to file\n",
    "    data_train = {'X_train': X_train,'y_train': y_train }\n",
    "\n",
    "    with open('../data/data_train_BBCrop_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(data_train, f)\n",
    "\n",
    "#rescale\n",
    "X_train = X_train / 255.\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=None, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15583, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=[0.9,1.1],\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BatchSize, shuffle=True, seed=None)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True)\n",
    "    #featurewise_std_normalization=True)\n",
    "    #rescale=1./255\n",
    "valid_datagen.fit(X_valid)   \n",
    "valid_generator = valid_datagen.flow(X_valid, y_valid, batch_size=BatchSize, shuffle=True, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='./checkpoints/checkpoint2/weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "        \n",
    "learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs/log2', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 1.6035 - acc: 0.4657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1470: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 1.40994, saving model to ./checkpoints/checkpoint2/weights.000-1.4099.hdf5\n",
      "15616/15583 [==============================] - 258s - loss: 1.5997 - acc: 0.4674 - val_loss: 1.4099 - val_acc: 0.7684\n",
      "Epoch 2/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 1.2052 - acc: 0.6913Epoch 00001: val_loss improved from 1.40994 to 1.31298, saving model to ./checkpoints/checkpoint2/weights.001-1.3130.hdf5\n",
      "15616/15583 [==============================] - 248s - loss: 1.2042 - acc: 0.6918 - val_loss: 1.3130 - val_acc: 0.7530\n",
      "Epoch 3/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 1.0535 - acc: 0.7477Epoch 00002: val_loss improved from 1.31298 to 1.24456, saving model to ./checkpoints/checkpoint2/weights.002-1.2446.hdf5\n",
      "15645/15583 [==============================] - 250s - loss: 1.0546 - acc: 0.7473 - val_loss: 1.2446 - val_acc: 0.7581\n",
      "Epoch 4/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.9817 - acc: 0.7552Epoch 00003: val_loss improved from 1.24456 to 1.19633, saving model to ./checkpoints/checkpoint2/weights.003-1.1963.hdf5\n",
      "15616/15583 [==============================] - 248s - loss: 0.9808 - acc: 0.7554 - val_loss: 1.1963 - val_acc: 0.7629\n",
      "Epoch 5/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.9017 - acc: 0.7675Epoch 00004: val_loss improved from 1.19633 to 1.17751, saving model to ./checkpoints/checkpoint2/weights.004-1.1775.hdf5\n",
      "15616/15583 [==============================] - 247s - loss: 0.9014 - acc: 0.7678 - val_loss: 1.1775 - val_acc: 0.7596\n",
      "Epoch 6/30\n",
      " 6528/15583 [===========>..................] - ETA: 115s - loss: 0.8754 - acc: 0.7782"
     ]
    }
   ],
   "source": [
    "#Resnet50\n",
    "#stg1 training\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = LeakyReLU(alpha=0.33)(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = LeakyReLU(alpha=0.33)(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(FISH_CLASSES), init='glorot_normal', activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=30, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints file weights.028-0.4157.hdf5\n",
      "0 input_1\n",
      "1 zeropadding2d_1\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 maxpooling2d_1\n",
      "6 res2a_branch2a\n",
      "7 bn2a_branch2a\n",
      "8 activation_2\n",
      "9 res2a_branch2b\n",
      "10 bn2a_branch2b\n",
      "11 activation_3\n",
      "12 res2a_branch2c\n",
      "13 res2a_branch1\n",
      "14 bn2a_branch2c\n",
      "15 bn2a_branch1\n",
      "16 merge_1\n",
      "17 activation_4\n",
      "18 res2b_branch2a\n",
      "19 bn2b_branch2a\n",
      "20 activation_5\n",
      "21 res2b_branch2b\n",
      "22 bn2b_branch2b\n",
      "23 activation_6\n",
      "24 res2b_branch2c\n",
      "25 bn2b_branch2c\n",
      "26 merge_2\n",
      "27 activation_7\n",
      "28 res2c_branch2a\n",
      "29 bn2c_branch2a\n",
      "30 activation_8\n",
      "31 res2c_branch2b\n",
      "32 bn2c_branch2b\n",
      "33 activation_9\n",
      "34 res2c_branch2c\n",
      "35 bn2c_branch2c\n",
      "36 merge_3\n",
      "37 activation_10\n",
      "38 res3a_branch2a\n",
      "39 bn3a_branch2a\n",
      "40 activation_11\n",
      "41 res3a_branch2b\n",
      "42 bn3a_branch2b\n",
      "43 activation_12\n",
      "44 res3a_branch2c\n",
      "45 res3a_branch1\n",
      "46 bn3a_branch2c\n",
      "47 bn3a_branch1\n",
      "48 merge_4\n",
      "49 activation_13\n",
      "50 res3b_branch2a\n",
      "51 bn3b_branch2a\n",
      "52 activation_14\n",
      "53 res3b_branch2b\n",
      "54 bn3b_branch2b\n",
      "55 activation_15\n",
      "56 res3b_branch2c\n",
      "57 bn3b_branch2c\n",
      "58 merge_5\n",
      "59 activation_16\n",
      "60 res3c_branch2a\n",
      "61 bn3c_branch2a\n",
      "62 activation_17\n",
      "63 res3c_branch2b\n",
      "64 bn3c_branch2b\n",
      "65 activation_18\n",
      "66 res3c_branch2c\n",
      "67 bn3c_branch2c\n",
      "68 merge_6\n",
      "69 activation_19\n",
      "70 res3d_branch2a\n",
      "71 bn3d_branch2a\n",
      "72 activation_20\n",
      "73 res3d_branch2b\n",
      "74 bn3d_branch2b\n",
      "75 activation_21\n",
      "76 res3d_branch2c\n",
      "77 bn3d_branch2c\n",
      "78 merge_7\n",
      "79 activation_22\n",
      "80 res4a_branch2a\n",
      "81 bn4a_branch2a\n",
      "82 activation_23\n",
      "83 res4a_branch2b\n",
      "84 bn4a_branch2b\n",
      "85 activation_24\n",
      "86 res4a_branch2c\n",
      "87 res4a_branch1\n",
      "88 bn4a_branch2c\n",
      "89 bn4a_branch1\n",
      "90 merge_8\n",
      "91 activation_25\n",
      "92 res4b_branch2a\n",
      "93 bn4b_branch2a\n",
      "94 activation_26\n",
      "95 res4b_branch2b\n",
      "96 bn4b_branch2b\n",
      "97 activation_27\n",
      "98 res4b_branch2c\n",
      "99 bn4b_branch2c\n",
      "100 merge_9\n",
      "101 activation_28\n",
      "102 res4c_branch2a\n",
      "103 bn4c_branch2a\n",
      "104 activation_29\n",
      "105 res4c_branch2b\n",
      "106 bn4c_branch2b\n",
      "107 activation_30\n",
      "108 res4c_branch2c\n",
      "109 bn4c_branch2c\n",
      "110 merge_10\n",
      "111 activation_31\n",
      "112 res4d_branch2a\n",
      "113 bn4d_branch2a\n",
      "114 activation_32\n",
      "115 res4d_branch2b\n",
      "116 bn4d_branch2b\n",
      "117 activation_33\n",
      "118 res4d_branch2c\n",
      "119 bn4d_branch2c\n",
      "120 merge_11\n",
      "121 activation_34\n",
      "122 res4e_branch2a\n",
      "123 bn4e_branch2a\n",
      "124 activation_35\n",
      "125 res4e_branch2b\n",
      "126 bn4e_branch2b\n",
      "127 activation_36\n",
      "128 res4e_branch2c\n",
      "129 bn4e_branch2c\n",
      "130 merge_12\n",
      "131 activation_37\n",
      "132 res4f_branch2a\n",
      "133 bn4f_branch2a\n",
      "134 activation_38\n",
      "135 res4f_branch2b\n",
      "136 bn4f_branch2b\n",
      "137 activation_39\n",
      "138 res4f_branch2c\n",
      "139 bn4f_branch2c\n",
      "140 merge_13\n",
      "141 activation_40\n",
      "142 res5a_branch2a\n",
      "143 bn5a_branch2a\n",
      "144 activation_41\n",
      "145 res5a_branch2b\n",
      "146 bn5a_branch2b\n",
      "147 activation_42\n",
      "148 res5a_branch2c\n",
      "149 res5a_branch1\n",
      "150 bn5a_branch2c\n",
      "151 bn5a_branch1\n",
      "152 merge_14\n",
      "153 activation_43\n",
      "154 res5b_branch2a\n",
      "155 bn5b_branch2a\n",
      "156 activation_44\n",
      "157 res5b_branch2b\n",
      "158 bn5b_branch2b\n",
      "159 activation_45\n",
      "160 res5b_branch2c\n",
      "161 bn5b_branch2c\n",
      "162 merge_15\n",
      "163 activation_46\n",
      "164 res5c_branch2a\n",
      "165 bn5c_branch2a\n",
      "166 activation_47\n",
      "167 res5c_branch2b\n",
      "168 bn5c_branch2b\n",
      "169 activation_48\n",
      "170 res5c_branch2c\n",
      "171 bn5c_branch2c\n",
      "172 merge_16\n",
      "173 activation_49\n",
      "174 avg_pool\n",
      "Epoch 1/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.2279 - acc: 0.9274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1470: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from 0.41571 to 0.22631, saving model to ./checkpoints/checkpoint2/weights.000-0.2263.hdf5\n",
      "15616/15583 [==============================] - 296s - loss: 0.2269 - acc: 0.9276 - val_loss: 0.2263 - val_acc: 0.9274\n",
      "Epoch 2/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.1277 - acc: 0.9603Epoch 00001: val_loss improved from 0.22631 to 0.15061, saving model to ./checkpoints/checkpoint2/weights.001-0.1506.hdf5\n",
      "15616/15583 [==============================] - 279s - loss: 0.1271 - acc: 0.9605 - val_loss: 0.1506 - val_acc: 0.9483\n",
      "Epoch 3/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9746Epoch 00002: val_loss improved from 0.15061 to 0.14083, saving model to ./checkpoints/checkpoint2/weights.002-0.1408.hdf5\n",
      "15645/15583 [==============================] - 283s - loss: 0.0818 - acc: 0.9746 - val_loss: 0.1408 - val_acc: 0.9619\n",
      "Epoch 4/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0592 - acc: 0.9818Epoch 00003: val_loss improved from 0.14083 to 0.07613, saving model to ./checkpoints/checkpoint2/weights.003-0.0761.hdf5\n",
      "15616/15583 [==============================] - 280s - loss: 0.0592 - acc: 0.9817 - val_loss: 0.0761 - val_acc: 0.9768\n",
      "Epoch 5/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0500 - acc: 0.9837Epoch 00004: val_loss improved from 0.07613 to 0.05647, saving model to ./checkpoints/checkpoint2/weights.004-0.0565.hdf5\n",
      "15616/15583 [==============================] - 280s - loss: 0.0499 - acc: 0.9838 - val_loss: 0.0565 - val_acc: 0.9844\n",
      "Epoch 6/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9856Epoch 00005: val_loss did not improve\n",
      "15645/15583 [==============================] - 280s - loss: 0.0470 - acc: 0.9856 - val_loss: 0.0788 - val_acc: 0.9776\n",
      "Epoch 7/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0330 - acc: 0.9899Epoch 00006: val_loss did not improve\n",
      "15616/15583 [==============================] - 279s - loss: 0.0330 - acc: 0.9899 - val_loss: 0.0611 - val_acc: 0.9836\n",
      "Epoch 8/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0307 - acc: 0.9892Epoch 00007: val_loss improved from 0.05647 to 0.05570, saving model to ./checkpoints/checkpoint2/weights.007-0.0557.hdf5\n",
      "15616/15583 [==============================] - 280s - loss: 0.0307 - acc: 0.9892 - val_loss: 0.0557 - val_acc: 0.9864\n",
      "Epoch 9/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9914Epoch 00008: val_loss did not improve\n",
      "15645/15583 [==============================] - 279s - loss: 0.0249 - acc: 0.9913 - val_loss: 0.0573 - val_acc: 0.9806\n",
      "Epoch 10/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0232 - acc: 0.9923Epoch 00009: val_loss did not improve\n",
      "15616/15583 [==============================] - 279s - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0644 - val_acc: 0.9846\n",
      "Epoch 11/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0188 - acc: 0.9939Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00010: reducing learning rate to 9.999999747378752e-06.\n",
      "15616/15583 [==============================] - 280s - loss: 0.0188 - acc: 0.9939 - val_loss: 0.0582 - val_acc: 0.9877\n",
      "Epoch 12/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9951Epoch 00011: val_loss did not improve\n",
      "15645/15583 [==============================] - 279s - loss: 0.0136 - acc: 0.9951 - val_loss: 0.0582 - val_acc: 0.9856\n",
      "Epoch 13/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0108 - acc: 0.9965Epoch 00012: val_loss improved from 0.05570 to 0.04757, saving model to ./checkpoints/checkpoint2/weights.012-0.0476.hdf5\n",
      "15616/15583 [==============================] - 279s - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0476 - val_acc: 0.9894\n",
      "Epoch 14/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0089 - acc: 0.9974Epoch 00013: val_loss did not improve\n",
      "15616/15583 [==============================] - 281s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0560 - val_acc: 0.9871\n",
      "Epoch 15/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9983Epoch 00014: val_loss improved from 0.04757 to 0.04754, saving model to ./checkpoints/checkpoint2/weights.014-0.0475.hdf5\n",
      "15645/15583 [==============================] - 281s - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0475 - val_acc: 0.9877\n",
      "Epoch 16/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0067 - acc: 0.9979Epoch 00015: val_loss did not improve\n",
      "15616/15583 [==============================] - 279s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0484 - val_acc: 0.9899\n",
      "Epoch 17/300\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.0070 - acc: 0.9980Epoch 00016: val_loss did not improve\n",
      "15616/15583 [==============================] - 280s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0489 - val_acc: 0.9894\n",
      "Epoch 18/300\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9979Epoch 00017: val_loss improved from 0.04754 to 0.04319, saving model to ./checkpoints/checkpoint2/weights.017-0.0432.hdf5\n",
      "15645/15583 [==============================] - 280s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0432 - val_acc: 0.9897\n",
      "Epoch 19/300\n",
      "11520/15583 [=====================>........] - ETA: 60s - loss: 0.0055 - acc: 0.9983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d52353edffa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=300, verbose=1, \n\u001b[1;32m     36\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningrate_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1450\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1452\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Resnet50\n",
    "#stg2 training\n",
    "\n",
    "# files = glob.glob('./checkpoints/*')\n",
    "# val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "# index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file weights.028-0.4157.hdf5')\n",
    "model = load_model('./checkpoints/checkpoint2/weights.028-0.4157.hdf5')\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "#164\n",
    "for layer in model.layers[:142]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[142:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=300, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints file ./checkpoints/checkpoint2/weights.004-1.1775.hdf5\n",
      "Epoch 1/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.8447 - acc: 0.7795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1470: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 1.02681, saving model to ./checkpoints/checkpoint2/weights.000-1.0268.hdf5\n",
      "15616/15583 [==============================] - 291s - loss: 0.8449 - acc: 0.7791 - val_loss: 1.0268 - val_acc: 0.7845\n",
      "Epoch 2/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.7952 - acc: 0.7880Epoch 00001: val_loss improved from 1.02681 to 0.96753, saving model to ./checkpoints/checkpoint2/weights.001-0.9675.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.7965 - acc: 0.7874 - val_loss: 0.9675 - val_acc: 0.7742\n",
      "Epoch 3/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.7733 - acc: 0.7930Epoch 00002: val_loss improved from 0.96753 to 0.84487, saving model to ./checkpoints/checkpoint2/weights.002-0.8449.hdf5\n",
      "15645/15583 [==============================] - 246s - loss: 0.7738 - acc: 0.7927 - val_loss: 0.8449 - val_acc: 0.7858\n",
      "Epoch 4/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.7238 - acc: 0.8014Epoch 00003: val_loss improved from 0.84487 to 0.74432, saving model to ./checkpoints/checkpoint2/weights.003-0.7443.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.7229 - acc: 0.8016 - val_loss: 0.7443 - val_acc: 0.7956\n",
      "Epoch 5/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.6864 - acc: 0.8053Epoch 00004: val_loss improved from 0.74432 to 0.66074, saving model to ./checkpoints/checkpoint2/weights.004-0.6607.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.6862 - acc: 0.8055 - val_loss: 0.6607 - val_acc: 0.8145\n",
      "Epoch 6/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.6779 - acc: 0.8114Epoch 00005: val_loss did not improve\n",
      "15645/15583 [==============================] - 243s - loss: 0.6774 - acc: 0.8113 - val_loss: 0.6671 - val_acc: 0.8128\n",
      "Epoch 7/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.6503 - acc: 0.8161Epoch 00006: val_loss improved from 0.66074 to 0.61099, saving model to ./checkpoints/checkpoint2/weights.006-0.6110.hdf5\n",
      "15616/15583 [==============================] - 243s - loss: 0.6512 - acc: 0.8159 - val_loss: 0.6110 - val_acc: 0.8296\n",
      "Epoch 8/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.6273 - acc: 0.8212Epoch 00007: val_loss improved from 0.61099 to 0.57337, saving model to ./checkpoints/checkpoint2/weights.007-0.5734.hdf5\n",
      "15616/15583 [==============================] - 243s - loss: 0.6275 - acc: 0.8210 - val_loss: 0.5734 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.6079 - acc: 0.8246Epoch 00008: val_loss did not improve\n",
      "15645/15583 [==============================] - 243s - loss: 0.6074 - acc: 0.8247 - val_loss: 0.5836 - val_acc: 0.8400\n",
      "Epoch 10/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5763 - acc: 0.8347Epoch 00009: val_loss improved from 0.57337 to 0.56416, saving model to ./checkpoints/checkpoint2/weights.009-0.5642.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.5781 - acc: 0.8341 - val_loss: 0.5642 - val_acc: 0.8364\n",
      "Epoch 11/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5825 - acc: 0.8301Epoch 00010: val_loss improved from 0.56416 to 0.54485, saving model to ./checkpoints/checkpoint2/weights.010-0.5449.hdf5\n",
      "15616/15583 [==============================] - 245s - loss: 0.5827 - acc: 0.8299 - val_loss: 0.5449 - val_acc: 0.8521\n",
      "Epoch 12/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.8332Epoch 00011: val_loss did not improve\n",
      "15645/15583 [==============================] - 245s - loss: 0.5695 - acc: 0.8334 - val_loss: 0.5657 - val_acc: 0.8354\n",
      "Epoch 13/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5466 - acc: 0.8388Epoch 00012: val_loss improved from 0.54485 to 0.51763, saving model to ./checkpoints/checkpoint2/weights.012-0.5176.hdf5\n",
      "15616/15583 [==============================] - 243s - loss: 0.5477 - acc: 0.8384 - val_loss: 0.5176 - val_acc: 0.8453\n",
      "Epoch 14/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5335 - acc: 0.8392Epoch 00013: val_loss did not improve\n",
      "15616/15583 [==============================] - 244s - loss: 0.5327 - acc: 0.8395 - val_loss: 0.5493 - val_acc: 0.8412\n",
      "Epoch 15/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.5479 - acc: 0.8333Epoch 00014: val_loss did not improve\n",
      "15645/15583 [==============================] - 245s - loss: 0.5478 - acc: 0.8332 - val_loss: 0.5256 - val_acc: 0.8445\n",
      "Epoch 16/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5158 - acc: 0.8450Epoch 00015: val_loss improved from 0.51763 to 0.49916, saving model to ./checkpoints/checkpoint2/weights.015-0.4992.hdf5\n",
      "15616/15583 [==============================] - 243s - loss: 0.5148 - acc: 0.8452 - val_loss: 0.4992 - val_acc: 0.8488\n",
      "Epoch 17/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.5124 - acc: 0.8461Epoch 00016: val_loss improved from 0.49916 to 0.47559, saving model to ./checkpoints/checkpoint2/weights.016-0.4756.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.5120 - acc: 0.8460 - val_loss: 0.4756 - val_acc: 0.8589\n",
      "Epoch 18/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.5098 - acc: 0.8424Epoch 00017: val_loss improved from 0.47559 to 0.47346, saving model to ./checkpoints/checkpoint2/weights.017-0.4735.hdf5\n",
      "15645/15583 [==============================] - 244s - loss: 0.5101 - acc: 0.8422 - val_loss: 0.4735 - val_acc: 0.8561\n",
      "Epoch 19/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4923 - acc: 0.8517Epoch 00018: val_loss did not improve\n",
      "15616/15583 [==============================] - 244s - loss: 0.4920 - acc: 0.8516 - val_loss: 0.4981 - val_acc: 0.8495\n",
      "Epoch 20/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4882 - acc: 0.8494Epoch 00019: val_loss did not improve\n",
      "15616/15583 [==============================] - 244s - loss: 0.4873 - acc: 0.8500 - val_loss: 0.4736 - val_acc: 0.8571\n",
      "Epoch 21/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.8485Epoch 00020: val_loss did not improve\n",
      "15645/15583 [==============================] - 244s - loss: 0.4865 - acc: 0.8486 - val_loss: 0.4805 - val_acc: 0.8541\n",
      "Epoch 22/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4708 - acc: 0.8549Epoch 00021: val_loss improved from 0.47346 to 0.45096, saving model to ./checkpoints/checkpoint2/weights.021-0.4510.hdf5\n",
      "15616/15583 [==============================] - 244s - loss: 0.4726 - acc: 0.8545 - val_loss: 0.4510 - val_acc: 0.8604\n",
      "Epoch 23/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4695 - acc: 0.8543Epoch 00022: val_loss did not improve\n",
      "15616/15583 [==============================] - 245s - loss: 0.4696 - acc: 0.8544 - val_loss: 0.4522 - val_acc: 0.8609\n",
      "Epoch 24/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8568Epoch 00023: val_loss improved from 0.45096 to 0.44584, saving model to ./checkpoints/checkpoint2/weights.023-0.4458.hdf5\n",
      "15645/15583 [==============================] - 245s - loss: 0.4592 - acc: 0.8568 - val_loss: 0.4458 - val_acc: 0.8647\n",
      "Epoch 25/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4600 - acc: 0.8564Epoch 00024: val_loss did not improve\n",
      "15616/15583 [==============================] - 244s - loss: 0.4607 - acc: 0.8563 - val_loss: 0.4470 - val_acc: 0.8606\n",
      "Epoch 26/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4460 - acc: 0.8596Epoch 00025: val_loss did not improve\n",
      "15616/15583 [==============================] - 245s - loss: 0.4466 - acc: 0.8596 - val_loss: 0.4531 - val_acc: 0.8591\n",
      "Epoch 27/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8580Epoch 00026: val_loss improved from 0.44584 to 0.42768, saving model to ./checkpoints/checkpoint2/weights.026-0.4277.hdf5\n",
      "15645/15583 [==============================] - 245s - loss: 0.4459 - acc: 0.8585 - val_loss: 0.4277 - val_acc: 0.8662\n",
      "Epoch 28/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4339 - acc: 0.8625Epoch 00027: val_loss did not improve\n",
      "15616/15583 [==============================] - 243s - loss: 0.4339 - acc: 0.8626 - val_loss: 0.4331 - val_acc: 0.8579\n",
      "Epoch 29/30\n",
      "15488/15583 [============================>.] - ETA: 1s - loss: 0.4316 - acc: 0.8619Epoch 00028: val_loss improved from 0.42768 to 0.41571, saving model to ./checkpoints/checkpoint2/weights.028-0.4157.hdf5\n",
      "15616/15583 [==============================] - 243s - loss: 0.4320 - acc: 0.8618 - val_loss: 0.4157 - val_acc: 0.8707\n",
      "Epoch 30/30\n",
      "15517/15583 [============================>.] - ETA: 0s - loss: 0.4340 - acc: 0.8630Epoch 00029: val_loss did not improve\n",
      "15645/15583 [==============================] - 244s - loss: 0.4337 - acc: 0.8630 - val_loss: 0.4198 - val_acc: 0.8669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c16fcce10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resume training\n",
    "\n",
    "files = glob.glob('./checkpoints/checkpoint2/*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch=len(X_train), nb_epoch=30, verbose=1, \n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=valid_generator, nb_val_samples=len(X_valid), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6037\n"
     ]
    }
   ],
   "source": [
    "#get bbox from detections_full_AGNOSTICnms.pkl\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "outputs = []\n",
    "count = np.zeros(len(detections_full_AGNOSTICnms))\n",
    "\n",
    "for im in range(len(detections_full_AGNOSTICnms)):\n",
    "    outputs_im = []\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if np.max(detects_im[i,5:]) >= CONF_THRESH:\n",
    "            outputs_im.append(detects_im[i,:]) \n",
    "    count[im] = len(outputs_im)\n",
    "    if len(outputs_im) == 0:\n",
    "        ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "        outputs_im.append(detects_im[ind,:])\n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    outputs.append(outputs_im)\n",
    "    \n",
    "#crop test images and cache to TEST_CROP_DIR\n",
    "\n",
    "# if not os.path.exists(TEST_CROP_DIR):\n",
    "#     os.mkdir(TEST_CROP_DIR)\n",
    "# files = glob.glob(TEST_CROP_DIR+'*')\n",
    "# for f in files:\n",
    "#     os.remove(f)\n",
    "    \n",
    "# with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "#     ims = f.readlines()\n",
    "# test_files = [im[:-1]+'.jpg' for im in ims]\n",
    "\n",
    "# for i in range(len(outputs)):\n",
    "#     if i%1000 == 0:\n",
    "#         print(i)\n",
    "#     filename = test_files[i]\n",
    "#     bboxes = outputs[i]\n",
    "#     basename, file_extension = os.path.splitext(filename) \n",
    "#     image = Image.open(TEST_DIR+filename)\n",
    "#     for j in range(len(bboxes)):\n",
    "#         bbox = bboxes[j]\n",
    "#         xmin = bbox[0]\n",
    "#         ymin = bbox[1]\n",
    "#         xmax = bbox[2]\n",
    "#         ymax = bbox[3]\n",
    "#         file_crop = TEST_CROP_DIR+basename+'_{}'.format(j)+'.jpg'\n",
    "#         cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "#         width_cropped, height_cropped = cropped.size\n",
    "#         if height_cropped > width_cropped: cropped = cropped.transpose(method=2)\n",
    "#         cropped.save(file_crop)\n",
    "        \n",
    "print(sum([outputs[i].shape[0] for i in range(len(outputs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_crop_preds = np.vstack(outputs)[:,4:]\n",
    "\n",
    "columns = ['NoF_RFCN', 'ALB_RFCN', 'BET_RFCN', 'DOL_RFCN', 'LAG_RFCN', 'OTHER_RFCN', 'SHARK_RFCN', 'YFT_RFCN']\n",
    "RFCN_preds_df = pd.DataFrame(test_crop_preds, columns=columns)\n",
    "\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims]\n",
    "\n",
    "test_crop_files_RFCN = []\n",
    "for i in range(len(outputs)):\n",
    "    filename = test_files[i]\n",
    "    basename, file_extension = os.path.splitext(filename) \n",
    "    for j in range(len(outputs[i])):\n",
    "        file_crop = basename+'_{}_'.format(j)+'.jpg'\n",
    "        test_crop_files_RFCN.append(file_crop)\n",
    "        \n",
    "RFCN_preds_df.insert(0, 'test_crop_files', test_crop_files_RFCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_crop_files</th>\n",
       "      <th>NoF_RFCN</th>\n",
       "      <th>ALB_RFCN</th>\n",
       "      <th>BET_RFCN</th>\n",
       "      <th>DOL_RFCN</th>\n",
       "      <th>LAG_RFCN</th>\n",
       "      <th>OTHER_RFCN</th>\n",
       "      <th>SHARK_RFCN</th>\n",
       "      <th>YFT_RFCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00005_0_.jpg</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.765914e-08</td>\n",
       "      <td>2.145238e-07</td>\n",
       "      <td>5.994206e-07</td>\n",
       "      <td>2.103843e-07</td>\n",
       "      <td>1.282200e-07</td>\n",
       "      <td>2.089381e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00007_0_.jpg</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>6.000044e-05</td>\n",
       "      <td>3.268235e-06</td>\n",
       "      <td>8.629868e-07</td>\n",
       "      <td>9.324418e-08</td>\n",
       "      <td>3.096656e-06</td>\n",
       "      <td>9.997229e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009_0_.jpg</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>9.396088e-04</td>\n",
       "      <td>7.386075e-07</td>\n",
       "      <td>6.028753e-07</td>\n",
       "      <td>1.481739e-04</td>\n",
       "      <td>6.061006e-07</td>\n",
       "      <td>2.904518e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00009_1_.jpg</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>2.547039e-03</td>\n",
       "      <td>2.058682e-07</td>\n",
       "      <td>4.018886e-07</td>\n",
       "      <td>1.093486e-04</td>\n",
       "      <td>4.156222e-07</td>\n",
       "      <td>9.210435e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00009_2_.jpg</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.985716</td>\n",
       "      <td>4.040803e-04</td>\n",
       "      <td>3.505660e-05</td>\n",
       "      <td>7.493963e-05</td>\n",
       "      <td>2.543065e-03</td>\n",
       "      <td>9.936455e-06</td>\n",
       "      <td>6.904111e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_crop_files  NoF_RFCN  ALB_RFCN      BET_RFCN      DOL_RFCN  \\\n",
       "0  img_00005_0_.jpg  0.999997  0.000002  7.765914e-08  2.145238e-07   \n",
       "1  img_00007_0_.jpg  0.000127  0.000083  6.000044e-05  3.268235e-06   \n",
       "2  img_00009_0_.jpg  0.000411  0.998497  9.396088e-04  7.386075e-07   \n",
       "3  img_00009_1_.jpg  0.000080  0.997262  2.547039e-03  2.058682e-07   \n",
       "4  img_00009_2_.jpg  0.011148  0.985716  4.040803e-04  3.505660e-05   \n",
       "\n",
       "       LAG_RFCN    OTHER_RFCN    SHARK_RFCN      YFT_RFCN  \n",
       "0  5.994206e-07  2.103843e-07  1.282200e-07  2.089381e-07  \n",
       "1  8.629868e-07  9.324418e-08  3.096656e-06  9.997229e-01  \n",
       "2  6.028753e-07  1.481739e-04  6.061006e-07  2.904518e-06  \n",
       "3  4.018886e-07  1.093486e-04  4.156222e-07  9.210435e-07  \n",
       "4  7.493963e-05  2.543065e-03  9.936455e-06  6.904111e-05  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFCN_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exist data_test_BBCrop_224_224.pickle. Loading test data from file.\n"
     ]
    }
   ],
   "source": [
    "#Load test data\n",
    "\n",
    "import datetime\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = Image.open(src)\n",
    "    im = im.resize((COLS, ROWS), Image.BILINEAR)\n",
    "    im = np.asarray(im)\n",
    "    return im\n",
    "\n",
    "if os.path.exists('../data/data_test_BBCrop_{}_{}.pickle'.format(ROWS, COLS)):\n",
    "    print ('Exist data_test_BBCrop_{}_{}.pickle. Loading test data from file.'.format(ROWS, COLS))\n",
    "    with open('../data/data_test_BBCrop_{}_{}.pickle'.format(ROWS, COLS), 'rb') as f:\n",
    "        data_test = pickle.load(f)\n",
    "    X_test_crop = data_test['X_test_crop']\n",
    "    test_crop_files = data_test['test_crop_files']\n",
    "else:\n",
    "    print ('Loading test data from original images. Generating data_test_BBCrop_{}_{}.pickle.'.format(ROWS, COLS))\n",
    "\n",
    "    test_crop_files = sorted([im for im in os.listdir(TEST_CROP_DIR)])\n",
    "    X_test_crop = np.ndarray((len(test_crop_files), ROWS, COLS, 3), dtype=np.uint8)\n",
    "\n",
    "    for i, im in enumerate(test_crop_files): \n",
    "        X_test_crop[i] = read_image(TEST_CROP_DIR+im)\n",
    "        if i%1000 == 0: print('Processed {} of {}'.format(i, len(test_crop_files)))\n",
    "            \n",
    "    data_test = {'X_test_crop': X_test_crop,'test_crop_files': test_crop_files }\n",
    "    \n",
    "    with open('../data/data_test_BBCrop_{}_{}.pickle'.format(ROWS, COLS), 'wb') as f:\n",
    "        pickle.dump(data_test, f, protocol=4)\n",
    "        \n",
    "X_test_crop = X_test_crop / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from weights.004-0.0565.hdf5\n",
      "6037/6037 [==============================] - 66s    \n"
     ]
    }
   ],
   "source": [
    "print('Loading model from weights.004-0.0565.hdf5')\n",
    "model = load_model('./checkpoints/checkpoint2/weights.004-0.0565.hdf5')\n",
    "test_crop_preds = model.predict(X_test_crop, batch_size=BatchSize, verbose=1)\n",
    "\n",
    "columns = ['ALB_BBCROP', 'BET_BBCROP', 'DOL_BBCROP', 'LAG_BBCROP', 'NoF_BBCROP', 'OTHER_BBCROP', 'SHARK_BBCROP', 'YFT_BBCROP']\n",
    "BBCROP_preds_df = pd.DataFrame(test_crop_preds, columns=columns)\n",
    "\n",
    "test_crop_files_BBCROP = test_crop_files\n",
    "BBCROP_preds_df.insert(0, 'test_crop_files', test_crop_files_BBCROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_crop_files</th>\n",
       "      <th>ALB_BBCROP</th>\n",
       "      <th>BET_BBCROP</th>\n",
       "      <th>DOL_BBCROP</th>\n",
       "      <th>LAG_BBCROP</th>\n",
       "      <th>NoF_BBCROP</th>\n",
       "      <th>OTHER_BBCROP</th>\n",
       "      <th>SHARK_BBCROP</th>\n",
       "      <th>YFT_BBCROP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00003_0_.jpg</td>\n",
       "      <td>0.650035</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.303847</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.032382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00003_1_.jpg</td>\n",
       "      <td>0.612278</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.353335</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.023469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00003_2_.jpg</td>\n",
       "      <td>0.828563</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.079166</td>\n",
       "      <td>0.040010</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.049815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00003_3_.jpg</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.923263</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.027163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00004_0_.jpg</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.018004</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.969516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_crop_files  ALB_BBCROP  BET_BBCROP  DOL_BBCROP  LAG_BBCROP  \\\n",
       "0  img_00003_0_.jpg    0.650035    0.000031    0.000032    0.303847   \n",
       "1  img_00003_1_.jpg    0.612278    0.000123    0.000318    0.007562   \n",
       "2  img_00003_2_.jpg    0.828563    0.000930    0.000137    0.079166   \n",
       "3  img_00003_3_.jpg    0.035011    0.000273    0.000792    0.003410   \n",
       "4  img_00004_0_.jpg    0.001726    0.005767    0.002891    0.000089   \n",
       "\n",
       "   NoF_BBCROP  OTHER_BBCROP  SHARK_BBCROP  YFT_BBCROP  \n",
       "0    0.013463      0.000206      0.000004    0.032382  \n",
       "1    0.353335      0.000562      0.002353    0.023469  \n",
       "2    0.040010      0.001362      0.000018    0.049815  \n",
       "3    0.923263      0.005048      0.005040    0.027163  \n",
       "4    0.018004      0.000043      0.001965    0.969516  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBCROP_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds_df = pd.merge(RFCN_preds_df, BBCROP_preds_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in FISH_CLASSES:\n",
    "    test_preds_df[c+'_RFCN-BBCROP'] = test_preds_df[c+'_RFCN'] - test_preds_df[c+'_BBCROP']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_diff = [c+'_RFCN-BBCROP' for c in FISH_CLASSES]\n",
    "test_preds_df['max_diff'] = test_preds_df[columns_diff].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_crop_files</th>\n",
       "      <th>NoF_RFCN</th>\n",
       "      <th>ALB_RFCN</th>\n",
       "      <th>BET_RFCN</th>\n",
       "      <th>DOL_RFCN</th>\n",
       "      <th>LAG_RFCN</th>\n",
       "      <th>OTHER_RFCN</th>\n",
       "      <th>SHARK_RFCN</th>\n",
       "      <th>YFT_RFCN</th>\n",
       "      <th>ALB_BBCROP</th>\n",
       "      <th>...</th>\n",
       "      <th>YFT_BBCROP</th>\n",
       "      <th>ALB_RFCN-BBCROP</th>\n",
       "      <th>BET_RFCN-BBCROP</th>\n",
       "      <th>DOL_RFCN-BBCROP</th>\n",
       "      <th>LAG_RFCN-BBCROP</th>\n",
       "      <th>NoF_RFCN-BBCROP</th>\n",
       "      <th>OTHER_RFCN-BBCROP</th>\n",
       "      <th>SHARK_RFCN-BBCROP</th>\n",
       "      <th>YFT_RFCN-BBCROP</th>\n",
       "      <th>max_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009_0_.jpg</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>7.386075e-07</td>\n",
       "      <td>6.028753e-07</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>6.061006e-07</td>\n",
       "      <td>2.904518e-06</td>\n",
       "      <td>0.185161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>0.813336</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.005766</td>\n",
       "      <td>-0.023524</td>\n",
       "      <td>-0.713069</td>\n",
       "      <td>-0.013078</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>-0.051029</td>\n",
       "      <td>0.813336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00009_1_.jpg</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>2.058682e-07</td>\n",
       "      <td>4.018886e-07</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>4.156222e-07</td>\n",
       "      <td>9.210435e-07</td>\n",
       "      <td>0.171151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.826110</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.047888</td>\n",
       "      <td>-0.777867</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.002430</td>\n",
       "      <td>0.826110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img_00027_0_.jpg</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>6.229545e-05</td>\n",
       "      <td>2.735355e-05</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>2.124482e-05</td>\n",
       "      <td>5.801505e-04</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.987671</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>-0.991083</td>\n",
       "      <td>-0.003992</td>\n",
       "      <td>0.987671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>img_00053_0_.jpg</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.995045</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3.611618e-05</td>\n",
       "      <td>4.381267e-05</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1.218681e-05</td>\n",
       "      <td>1.179397e-03</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.952344</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.952430</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.952344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>img_00102_1_.jpg</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.996992</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.210032e-06</td>\n",
       "      <td>2.301208e-06</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>8.039682e-06</td>\n",
       "      <td>4.455090e-04</td>\n",
       "      <td>0.078716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.913665</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.003913</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.918276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>img_00138_0_.jpg</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>4.470697e-05</td>\n",
       "      <td>5.833802e-05</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.139192e-05</td>\n",
       "      <td>2.583566e-03</td>\n",
       "      <td>0.085957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.907972</td>\n",
       "      <td>-0.001575</td>\n",
       "      <td>-0.001822</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.898538</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.907972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>img_00170_0_.jpg</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.970260</td>\n",
       "      <td>2.192429e-04</td>\n",
       "      <td>9.156979e-03</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>7.300457e-05</td>\n",
       "      <td>2.405520e-03</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.963460</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.262183</td>\n",
       "      <td>-0.668788</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.014292</td>\n",
       "      <td>0.963460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>img_00223_0_.jpg</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.995250</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>7.540416e-05</td>\n",
       "      <td>1.170128e-04</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>1.148711e-04</td>\n",
       "      <td>1.185521e-03</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.890486</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.891655</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.890486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>img_00232_0_.jpg</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>9.505967e-05</td>\n",
       "      <td>4.251345e-06</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>9.889659e-01</td>\n",
       "      <td>1.038441e-04</td>\n",
       "      <td>0.059854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>-0.059762</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.914922</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.977409</td>\n",
       "      <td>-0.003693</td>\n",
       "      <td>0.977409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>img_00282_0_.jpg</td>\n",
       "      <td>0.051981</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.735692e-04</td>\n",
       "      <td>3.506795e-05</td>\n",
       "      <td>0.947223</td>\n",
       "      <td>3.669118e-05</td>\n",
       "      <td>7.468431e-05</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>-0.025179</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>-0.916746</td>\n",
       "      <td>0.945165</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>0.945165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_crop_files  NoF_RFCN  ALB_RFCN  BET_RFCN      DOL_RFCN  \\\n",
       "2   img_00009_0_.jpg  0.000411  0.998497  0.000940  7.386075e-07   \n",
       "3   img_00009_1_.jpg  0.000080  0.997262  0.002547  2.058682e-07   \n",
       "7   img_00027_0_.jpg  0.000204  0.989823  0.004538  6.229545e-05   \n",
       "11  img_00053_0_.jpg  0.003392  0.995045  0.000144  3.611618e-05   \n",
       "17  img_00102_1_.jpg  0.002490  0.996992  0.000017  1.210032e-06   \n",
       "28  img_00138_0_.jpg  0.002167  0.993929  0.000827  4.470697e-05   \n",
       "33  img_00170_0_.jpg  0.010553  0.005909  0.970260  2.192429e-04   \n",
       "40  img_00223_0_.jpg  0.001502  0.995250  0.000643  7.540416e-05   \n",
       "45  img_00232_0_.jpg  0.002118  0.000092  0.000109  9.505967e-05   \n",
       "49  img_00282_0_.jpg  0.051981  0.000411  0.000065  1.735692e-04   \n",
       "\n",
       "        LAG_RFCN  OTHER_RFCN    SHARK_RFCN      YFT_RFCN  ALB_BBCROP  \\\n",
       "2   6.028753e-07    0.000148  6.061006e-07  2.904518e-06    0.185161   \n",
       "3   4.018886e-07    0.000109  4.156222e-07  9.210435e-07    0.171151   \n",
       "7   2.735355e-05    0.004744  2.124482e-05  5.801505e-04    0.002152   \n",
       "11  4.381267e-05    0.000147  1.218681e-05  1.179397e-03    0.042701   \n",
       "17  2.301208e-06    0.000044  8.039682e-06  4.455090e-04    0.078716   \n",
       "28  5.833802e-05    0.000369  2.139192e-05  2.583566e-03    0.085957   \n",
       "33  9.156979e-03    0.001424  7.300457e-05  2.405520e-03    0.024338   \n",
       "40  1.170128e-04    0.001112  1.148711e-04  1.185521e-03    0.104764   \n",
       "45  4.251345e-06    0.008513  9.889659e-01  1.038441e-04    0.059854   \n",
       "49  3.506795e-05    0.947223  3.669118e-05  7.468431e-05    0.025590   \n",
       "\n",
       "      ...     YFT_BBCROP  ALB_RFCN-BBCROP  BET_RFCN-BBCROP  DOL_RFCN-BBCROP  \\\n",
       "2     ...       0.051031         0.813336        -0.006452        -0.005766   \n",
       "3     ...       0.002431         0.826110         0.002122        -0.000092   \n",
       "7     ...       0.004572         0.987671         0.004517        -0.000097   \n",
       "11    ...       0.000060         0.952344         0.000061        -0.000049   \n",
       "17    ...       0.000295         0.918276        -0.000037        -0.000056   \n",
       "28    ...       0.002670         0.907972        -0.001575        -0.001822   \n",
       "33    ...       0.016697        -0.018429         0.963460         0.000004   \n",
       "40    ...       0.000118         0.890486         0.000572        -0.000239   \n",
       "45    ...       0.003797        -0.059762        -0.002659        -0.000338   \n",
       "49    ...       0.000721        -0.025179        -0.000539        -0.000470   \n",
       "\n",
       "    LAG_RFCN-BBCROP  NoF_RFCN-BBCROP  OTHER_RFCN-BBCROP  SHARK_RFCN-BBCROP  \\\n",
       "2         -0.023524        -0.713069          -0.013078          -0.000419   \n",
       "3         -0.047888        -0.777867           0.000055          -0.000010   \n",
       "7          0.000019        -0.000363           0.003326          -0.991083   \n",
       "11        -0.000620        -0.952430          -0.000061          -0.000363   \n",
       "17        -0.000343        -0.913665          -0.000414          -0.003913   \n",
       "28        -0.005077        -0.898538          -0.000104          -0.000770   \n",
       "33        -0.262183        -0.668788           0.000420          -0.000193   \n",
       "40        -0.000713        -0.891655           0.000971          -0.000489   \n",
       "45        -0.003148        -0.914922           0.007113           0.977409   \n",
       "49        -0.000421        -0.916746           0.945165          -0.001164   \n",
       "\n",
       "    YFT_RFCN-BBCROP  max_diff  \n",
       "2         -0.051029  0.813336  \n",
       "3         -0.002430  0.826110  \n",
       "7         -0.003992  0.987671  \n",
       "11         0.001119  0.952344  \n",
       "17         0.000151  0.918276  \n",
       "28        -0.000087  0.907972  \n",
       "33        -0.014292  0.963460  \n",
       "40         0.001067  0.890486  \n",
       "45        -0.003693  0.977409  \n",
       "49        -0.000646  0.945165  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_df[test_preds_df[\"max_diff\"]>=0.8].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from weights.003-0.0761.hdf5\n",
      "6037/6037 [==============================] - 64s    \n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "#test preds clsMaxAve\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "# files = glob.glob('./checkpoints/checkpoint2/*')\n",
    "# val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "# index = val_losses.index(min(val_losses))\n",
    "# print('Loading model from', files[index])\n",
    "# model = load_model(files[index])\n",
    "print('Loading model from weights.004-0.0565.hdf5')\n",
    "model = load_model('./checkpoints/checkpoint2/weights.004-0.0565.hdf5')\n",
    "\n",
    "test_crop_preds = model.predict(X_test_crop, batch_size=BatchSize, verbose=1)\n",
    "#test_crop_preds = np.vstack(outputs)[:,4:]\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims]\n",
    "\n",
    "count = np.zeros(len(test_files))\n",
    "\n",
    "test_preds = np.ndarray((len(test_files), test_crop_preds.shape[1]), dtype=np.float32)\n",
    "for j in range(len(test_files)):\n",
    "    if j%1000 == 0:\n",
    "        print(j)\n",
    "    file = test_files[j]\n",
    "    test_preds_im = []\n",
    "    for i in range(len(test_crop_files)):\n",
    "        if test_crop_files[i][:9] == file[:9]:\n",
    "            test_preds_im.append(test_crop_preds[i])\n",
    "    test_preds_im = np.asarray(test_preds_im)\n",
    "    score_max = np.max(test_preds_im, axis=1)\n",
    "    inds = np.argmax(test_preds_im, axis=1)\n",
    "    labels = [FISH_CLASSES[ind] for ind in inds]\n",
    "    columns = FISH_CLASSES[:]\n",
    "    test_preds_im_df = pd.DataFrame(test_preds_im, columns=columns)\n",
    "    test_preds_im_df['max_cls'] = labels\n",
    "    test_preds_im_df['max_score'] = score_max \n",
    "    test_preds_im_df['Counts'] = test_preds_im_df.groupby(['max_cls'])['max_cls'].transform('count')\n",
    "    idx = test_preds_im_df.groupby(['max_cls'])['max_score'].transform(max) == test_preds_im_df['max_score']\n",
    "    test_preds_im_df = test_preds_im_df[idx]\n",
    "    count[j] = test_preds_im_df.shape[0]\n",
    "    l = FISH_CLASSES.copy()\n",
    "    l.append('Counts')\n",
    "    test_preds_im_array = test_preds_im_df[l].as_matrix() \n",
    "    test_preds[j] = np.average(test_preds_im_array[:,:-1], axis=0, weights=test_preds_im_array[:,-1], returned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temperature\n",
    "T = 2.5\n",
    "test_preds_T = np.exp(np.log(test_preds)/T)\n",
    "test_preds_T = test_preds_T/np.sum(test_preds_T, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of train is 0.9195452458092187\n"
     ]
    }
   ],
   "source": [
    "#calculate train logloss\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "#FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "train_files = test_files[1000:]\n",
    "train_preds = test_preds_T[1000:,:]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_file_labels = f.readlines()\n",
    "\n",
    "log_losses = []\n",
    "for i in range(len(train_preds)):\n",
    "    im = train_files[i][:-4]\n",
    "    for im_label in train_file_labels:\n",
    "        if im_label[:9] == im:\n",
    "            label = im_label[10:-1]\n",
    "            index = FISH_CLASSES.index(label)\n",
    "            log_losses.append(-math.log(train_preds[i,index]))\n",
    "log_loss = sum(log_losses) / float(len(log_losses))\n",
    "print('logloss of train is', log_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test submission\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "submission = pd.DataFrame(test_preds_T[:1000,:], columns=FISH_CLASSES)\n",
    "submission.insert(0, 'image', test_files[:1000])\n",
    "\n",
    "info = 'RFCN_AGONOSTICnms_'+RFCN_MODEL+'_BBCROP_resnet50_clsMaxAve_conf{:.2f}_T{}_'.format(CONF_THRESH, T) + '{:.4f}'.format(log_loss)\n",
    "sub_file = 'submission_' + info + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###clear checkpoints folder\n",
    "\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.mkdir('./checkpoints')\n",
    "files = glob.glob('./checkpoints/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###clear logs folder\n",
    "\n",
    "if not os.path.exists('./logs'):\n",
    "    os.mkdir('./logs')\n",
    "files = glob.glob('./logs/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
