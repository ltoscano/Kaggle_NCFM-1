{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import collections, math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#crop test images by detections_full_AGNOSTICnms.pkl 取同类中score最高的，按类的数量加权平均\n",
    "\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.8\n",
    "outputs = []\n",
    "count = np.zeros(len(detections_full_AGNOSTICnms))\n",
    "\n",
    "for im in range(len(detections_full_AGNOSTICnms)):\n",
    "    if im%1000 == 0:\n",
    "        print(im)\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    score_max = np.max(detects_im[:,5:], axis=1)\n",
    "    inds = np.argmax(detects_im[:,5:], axis=1)\n",
    "    labels = [FISH_CLASSES[ind+1] for ind in inds]\n",
    "    columns = ['box1', 'box2', 'box3', 'box4']\n",
    "    columns.extend(FISH_CLASSES)\n",
    "    detects_im_df = pd.DataFrame(detects_im, columns=columns)\n",
    "    detects_im_df['max_cls'] = labels\n",
    "    detects_im_df['max_score'] = score_max\n",
    "    detects_im_df = detects_im_df[detects_im_df[\"max_score\"]>=CONF_THRESH]  \n",
    "    detects_im_df['Counts'] = detects_im_df.groupby(['max_cls'])['max_cls'].transform('count')\n",
    "    idx = detects_im_df.groupby(['max_cls'])['max_score'].transform(max) == detects_im_df['max_score']\n",
    "    detects_im_df = detects_im_df[idx]\n",
    "    detects_im_array = detects_im_df[columns].as_matrix()\n",
    "    count[im] = detects_im_array.shape[0]\n",
    "    if detects_im_array.shape[0] == 0:\n",
    "        ind = np.argmax(score_max)\n",
    "        outputs_im = detects_im[[ind], :]\n",
    "    else:\n",
    "        outputs_im = detects_im_array\n",
    "    outputs.append(outputs_im)\n",
    "\n",
    "print(sum([outputs[i].shape[0] for i in range(len(outputs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count8 = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections.Counter(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(count==2)[0]\n",
    "#np.ndarray.tolist(np.where(count==2)[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = [(count5[i]-count9[i])>0 and count9[i]!=0 for i in range(4777)]\n",
    "ims_diff = []\n",
    "for i in range(1,2):\n",
    "    if diff[i] == True:\n",
    "        ims_diff.append(i)\n",
    "\n",
    "ims_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualize test image crop\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims]\n",
    "\n",
    "for j in np.ndarray.tolist(np.where(count==0)[0][-10:]):\n",
    "    dets = outputs[j]\n",
    "    print(dets)\n",
    "    im = Image.open(\"../RFCN/JPEGImages/\"+test_files[j])\n",
    "    im = np.asarray(im)\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in range(dets.shape[0]):\n",
    "        bbox = dets[i, :4]\n",
    "        score = np.amax(dets[i,4:])\n",
    "        index = np.argmax(dets[i,4:])\n",
    "        class_name = FISH_CLASSES[index]\n",
    "        #if not (bbox[0] == 0 and bbox[1] == 0 and bbox[2] == 0 and bbox[3] == 0):\n",
    "        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5))\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('Image {} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(j, class_name, CONF_THRESH),fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "#submission from detections_full_AGNOSTICnms.pkl 取同类中score最高的，按类的数量加权平均\n",
    "\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.9\n",
    "outputs = np.ndarray((len(detections_full_AGNOSTICnms), len(FISH_CLASSES)), dtype=np.float64)\n",
    "\n",
    "for im in range(len(detections_full_AGNOSTICnms)):\n",
    "    if im%1000 == 0:\n",
    "        print(im)\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    score_max = np.max(detects_im[:,5:], axis=1)\n",
    "    inds = np.argmax(detects_im[:,5:], axis=1)\n",
    "    labels = [FISH_CLASSES[ind+1] for ind in inds]\n",
    "    columns = ['box1', 'box2', 'box3', 'box4']\n",
    "    columns.extend(FISH_CLASSES)\n",
    "    detects_im_df = pd.DataFrame(detects_im, columns=columns)\n",
    "    detects_im_df['max_cls'] = labels\n",
    "    detects_im_df['max_score'] = score_max\n",
    "    detects_im_df = detects_im_df[detects_im_df[\"max_score\"]>=CONF_THRESH]  \n",
    "    detects_im_df['Counts'] = detects_im_df.groupby(['max_cls'])['max_cls'].transform('count')\n",
    "    idx = detects_im_df.groupby(['max_cls'])['max_score'].transform(max) == detects_im_df['max_score']\n",
    "    detects_im_df = detects_im_df[idx]\n",
    "    l = FISH_CLASSES.copy()\n",
    "    l.append('Counts')\n",
    "    detects_im_array = detects_im_df[l].as_matrix()\n",
    "    if detects_im_array.shape[0] == 0:\n",
    "        ind = np.argmax(score_max)\n",
    "        outputs_im = detects_im[ind,4:12]\n",
    "    else:\n",
    "        outputs_im = np.average(detects_im_array[:,:-1], axis=0, weights=detects_im_array[:,-1], returned=False)\n",
    "    outputs[im] = outputs_im\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of train is 0.1125375372472951\n"
     ]
    }
   ],
   "source": [
    "# CLIP_THRESH = 0.02\n",
    "# outputs_cliped = np.clip(outputs, CLIP_THRESH, 1, out=None)\n",
    "# outputs_cliped = outputs_cliped/np.sum(outputs_cliped, axis=1, keepdims=True)\n",
    "# test_preds = outputs_cliped[:1000]\n",
    "# train_preds = outputs_cliped[1000:]\n",
    "\n",
    "#temperature\n",
    "T = 2.5\n",
    "outputs_T = np.exp(np.log(outputs)/T)\n",
    "outputs_T = outputs_T/np.sum(outputs_T, axis=1, keepdims=True)\n",
    "test_preds = outputs_T[:1000]\n",
    "train_preds = outputs_T[1000:]\n",
    "\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims[:1000]]\n",
    "train_files = [im[:-1] for im in ims[1000:]]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_file_labels = f.readlines()\n",
    "\n",
    "log_losses = []\n",
    "for i in range(len(train_preds)):\n",
    "    im = train_files[i]\n",
    "    for im_label in train_file_labels:\n",
    "        if im == im_label[:9]:\n",
    "            label = im_label[10:-1]\n",
    "            index = FISH_CLASSES.index(label)\n",
    "            log_losses.append(-math.log(train_preds[i][index]))\n",
    "log_loss = sum(log_losses) / float(len(log_losses))\n",
    "print('logloss of train is', log_loss )\n",
    "\n",
    "import datetime\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "#submission.loc[:, 'image'] = pd.Series(test_files, index=submission.index)\n",
    "submission.insert(0, 'image', test_files)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "# info = 'RFCN_AGONOSTICnms_clsMaxAve_resnet101_rfcn_ohem_iter_30000_conf{:.1f}_'.format(CONF_THRESH) + 'clip{:.2f}_'.format(CLIP_THRESH) + '{:.4f}'.format(log_loss)\n",
    "info = 'RFCN_AGONOSTICnms_clsMaxAve_'+RFCN_MODEL+'_conf{:.2f}_T{}_'.format(CONF_THRESH, T) + '{:.4f}'.format(log_loss)\n",
    "sub_file = 'submission_' + info + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#crop test images by detections_full_AGNOSTICnms.pkl\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_resnet101_rfcn_ohem_iter_30000.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.5\n",
    "outputs = []\n",
    "count = np.zeros(len(detections_full_AGNOSTICnms))\n",
    "\n",
    "for im in range(len(detections_full_AGNOSTICnms)):\n",
    "    outputs_im = []\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if np.max(detects_im[i,5:]) >= CONF_THRESH:\n",
    "            outputs_im.append(detects_im[i,:]) \n",
    "    count[im] = len(outputs_im)\n",
    "    if len(outputs_im) == 0:\n",
    "        ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "        outputs_im.append(detects_im[ind,:])\n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    outputs.append(outputs_im)\n",
    "\n",
    "print(sum([outputs[i].shape[0] for i in range(len(outputs))]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#submission from detections_full_AGNOSTICnms.pkl\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_resnet101_rfcn_ohem_iter_30000.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.5\n",
    "outputs = np.ndarray((len(detections_full_AGNOSTICnms), len(FISH_CLASSES)), dtype=np.float64)\n",
    "\n",
    "for im in range(len(detections_full_AGNOSTICnms)):\n",
    "    outputs_im = []\n",
    "    detects_im = detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if np.max(detects_im[i,5:]) >= CONF_THRESH:\n",
    "            outputs_im.append(detects_im[i,:]) \n",
    "    if len(outputs_im) == 0:\n",
    "        ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "        l = [0,0,0,0]\n",
    "        l.extend(np.ndarray.tolist(detects_im[ind,4:]))\n",
    "        outputs_im.append(l)\n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    outputs[im] = np.mean(outputs_im, axis=0)[4:]\n",
    "\n",
    "CLIP_THRESH = 0.02\n",
    "outputs_cliped = np.clip(outputs, CLIP_THRESH, 1, out=None)\n",
    "outputs_cliped = outputs_cliped/np.sum(outputs_cliped, axis=1, keepdims=True)\n",
    "    \n",
    "test_preds = outputs_cliped[:1000]\n",
    "train_preds = outputs_cliped[1000:]\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims[:1000]]\n",
    "train_files = [im[:-1] for im in ims[1000:]]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_file_labels = f.readlines()\n",
    "\n",
    "log_losses = []\n",
    "for i in range(len(train_preds)):\n",
    "    im = train_files[i]\n",
    "    for im_label in train_file_labels:\n",
    "        if im == im_label[:9]:\n",
    "            label = im_label[10:-1]\n",
    "            index = FISH_CLASSES.index(label)\n",
    "            log_losses.append(-math.log(train_preds[i][index]))\n",
    "log_loss = sum(log_losses) / float(len(log_losses))\n",
    "print('logloss of train is', log_loss )\n",
    "\n",
    "import datetime\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "#submission.loc[:, 'image'] = pd.Series(test_files, index=submission.index)\n",
    "submission.insert(0, 'image', test_files)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "info = 'RFCN_AGONOSTICnms_resnet101_conf{:.1f}_'.format(CONF_THRESH) + 'clip{:.2f}_'.format(CLIP_THRESH) + '{:.4f}'.format(log_loss)\n",
    "sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#crop test images by detections_full.pkl\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_resnet101_rfcn_ohem_iter_30000.pkl','rb') as f:\n",
    "    detections_full = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.5\n",
    "outputs = []\n",
    "count = np.zeros(len(detections_full[0]))\n",
    "\n",
    "for im in range(len(detections_full[0])):\n",
    "    outputs_im = []\n",
    "    detects_im = []\n",
    "    for cls in range(1,len(FISH_CLASSES)):\n",
    "        detects_im_cls = detections_full[cls][im]\n",
    "        for i in range(len(detects_im_cls)):\n",
    "            if np.max(detects_im_cls[i,4+cls]) >= CONF_THRESH:\n",
    "                outputs_im.append(detects_im_cls[i,:]) \n",
    "    count[im] = len(outputs_im)\n",
    "    for cls in range(1,len(FISH_CLASSES)):  \n",
    "        detects_im.append(detections_full[cls][im])\n",
    "    detects_im = np.vstack(detects_im)\n",
    "    if len(outputs_im) == 0:\n",
    "        ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "        outputs_im.append(detects_im[ind,:])\n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    outputs.append(outputs_im)\n",
    "\n",
    "print(sum([outputs[i].shape[0] for i in range(len(outputs))]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#submission from detections_full.pkl\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "import pickle \n",
    "with open('../data/RFCN_detections/detections_full_resnet101_rfcn_ohem_iter_30000.pkl','rb') as f:\n",
    "    detections_full = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "CONF_THRESH = 0.5\n",
    "outputs = np.ndarray((len(detections_full[0]), len(FISH_CLASSES)), dtype=np.float64)\n",
    "\n",
    "for im in range(len(detections_full[0])):\n",
    "    outputs_im = []\n",
    "    detects_im = []\n",
    "    for cls in range(1,len(FISH_CLASSES)):\n",
    "        detects_im_cls = detections_full[cls][im]\n",
    "        for i in range(len(detects_im_cls)):\n",
    "            if np.max(detects_im_cls[i,4+cls]) >= CONF_THRESH:\n",
    "                outputs_im.append(detects_im_cls[i,:]) \n",
    "    for cls in range(1,len(FISH_CLASSES)):  \n",
    "        detects_im.append(detections_full[cls][im])\n",
    "    detects_im = np.vstack(detects_im)\n",
    "    if len(outputs_im) == 0:\n",
    "        ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "        outputs_im.append(detects_im[ind,:])\n",
    "    outputs_im = np.asarray(outputs_im)\n",
    "    outputs[im] = np.mean(outputs_im, axis=0)[4:]\n",
    "\n",
    "CLIP_THRESH = 0.02\n",
    "outputs_cliped = np.clip(outputs, CLIP_THRESH, 1, out=None)\n",
    "outputs_cliped = outputs_cliped/np.sum(outputs_cliped, axis=1, keepdims=True)\n",
    "    \n",
    "test_preds = outputs_cliped[:1000]\n",
    "train_preds = outputs_cliped[1000:]\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "    ims = f.readlines()\n",
    "test_files = [im[:-1]+'.jpg' for im in ims[:1000]]\n",
    "train_files = [im[:-1] for im in ims[1000:]]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_file_labels = f.readlines()\n",
    "\n",
    "log_losses = []\n",
    "for i in range(len(train_preds)):\n",
    "    im = train_files[i]\n",
    "    for im_label in train_file_labels:\n",
    "        if im == im_label[:9]:\n",
    "            label = im_label[10:-1]\n",
    "            index = FISH_CLASSES.index(label)\n",
    "            log_losses.append(-math.log(train_preds[i][index]))\n",
    "log_loss = sum(log_losses) / float(len(log_losses))\n",
    "print('logloss of train is', log_loss )\n",
    "\n",
    "import datetime\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "#submission.loc[:, 'image'] = pd.Series(test_files, index=submission.index)\n",
    "submission.insert(0, 'image', test_files)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "info = 'RFCN_resnet101_conf{:.2f}_'.format(CONF_THRESH) + 'clip{:.2f}_'.format(CLIP_THRESH) + '{:.4f}'.format(log_loss)\n",
    "sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "submission.to_csv(sub_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
