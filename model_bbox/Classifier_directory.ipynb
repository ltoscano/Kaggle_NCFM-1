{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random, glob, pickle, collections, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "CHECKPOINT_DIR = './checkpoints/checkpoint4/'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "CONF_THRESH = 0.8\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 128\n",
    "LearningRate = 1e-4\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# GT_crop_bboxs_df = ['image_class','image_file','crop_index','crop_class','x_min',''y_min','x_max','ymax']\n",
    "# like RCNN expand the crop by 16 pixels\n",
    "p=16        \n",
    "GT_crop_bboxs_df = pd.DataFrame(columns=['image_class','image_file','crop_index','crop_class','x_min','y_min','x_max','ymax'])  \n",
    "\n",
    "crop_classes=FISH_CLASSES[:]\n",
    "crop_classes.remove('NoF')\n",
    "\n",
    "for c in crop_classes:\n",
    "    print(c)\n",
    "    j = json.load(open('../data/BBannotations/{}.json'.format(c), 'r'))\n",
    "    for l in j: \n",
    "        filename = l[\"filename\"]\n",
    "        head, tail = os.path.split(filename)\n",
    "        basename, file_extension = os.path.splitext(tail) \n",
    "        image = Image.open(TRAIN_DIR+c+'/'+tail)\n",
    "        width_image, height_image = image.size\n",
    "        for i in range(len(l[\"annotations\"])):\n",
    "            a = l[\"annotations\"][i]\n",
    "            xmin = (a[\"x\"])\n",
    "            ymin = (a[\"y\"])\n",
    "            width = (a[\"width\"])\n",
    "            height = (a[\"height\"])\n",
    "            delta_width = p/(COLS-2*p)*width\n",
    "            delta_height = p/(ROWS-2*p)*height\n",
    "            xmin_expand = xmin-delta_width\n",
    "            ymin_expand = ymin-delta_height\n",
    "            xmax_expand = xmin+width+delta_width\n",
    "            ymax_expand = ymin+height+delta_height\n",
    "            assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "            assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "            GT_crop_bboxs_df.loc[len(GT_crop_bboxs_df)]=[c,tail,i,a[\"class\"],max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "            if a[\"class\"] != c: print(GT_crop_bboxs_df.tail(1))\n",
    "                \n",
    "\n",
    "#crop NoF by detections_full_AGNOSTICnms.pkl\n",
    "\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "\n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "train_detections_full_AGNOSTICnms = detections_full_AGNOSTICnms[1000:]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_files = f.readlines()\n",
    "assert len(train_detections_full_AGNOSTICnms) == len(train_files)\n",
    "\n",
    "\n",
    "num_NoF_perIm = 10\n",
    "\n",
    "for im in range(len(train_detections_full_AGNOSTICnms)):\n",
    "    if im%1000 == 0: print(im)\n",
    "        \n",
    "    basename = train_files[im][:9]\n",
    "    image_class = train_files[im][10:-1]\n",
    "    image = Image.open(TRAIN_DIR+image_class+'/'+basename+'.jpg')\n",
    "    width_image, height_image = image.size\n",
    "    \n",
    "    bboxes = []\n",
    "    detects_im = train_detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if detects_im[i,4] >= 0.999 and detects_im[i,2]<width_image and detects_im[i,3]<height_image:\n",
    "            bboxes.append(detects_im[i,:]) \n",
    "    bboxes = np.asarray(bboxes)\n",
    "    bboxes = bboxes[np.random.choice(bboxes.shape[0], num_NoF_perIm, replace=False), :]\n",
    "    \n",
    "    for j in range(len(bboxes)):    \n",
    "        bbox = bboxes[j]\n",
    "        xmin = bbox[0]\n",
    "        ymin = bbox[1]\n",
    "        xmax = bbox[2]\n",
    "        ymax = bbox[3]\n",
    "        width = xmax-xmin\n",
    "        height = ymax-ymin\n",
    "        delta_width = p/(COLS-2*p)*width\n",
    "        delta_height = p/(ROWS-2*p)*height\n",
    "        xmin_expand = xmin-delta_width\n",
    "        ymin_expand = ymin-delta_height\n",
    "        xmax_expand = xmax+delta_width\n",
    "        ymax_expand = ymax+delta_height\n",
    "        assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "        assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "        GT_crop_bboxs_df.loc[len(GT_crop_bboxs_df)]=[image_class,basename+'.jpg',j,'NoF',max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "    \n",
    "GT_crop_bboxs_df.to_pickle('../data/GT_crop_bboxs_df_directory.pickle')                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#visualization\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_files = f.readlines()\n",
    "\n",
    "for j in range(0,3777,500):\n",
    "    im = Image.open('../RFCN/JPEGImages/'+train_files[j][:9]+'.jpg')\n",
    "    im = np.asarray(im)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    GT_crops = GT_crop_bboxs_df.loc[GT_crop_bboxs_df['image_file']==(train_files[j][:9]+'.jpg')]\n",
    "    for index,row in GT_crops.iterrows():\n",
    "        row = row.tolist()\n",
    "        bbox = row[4:8]\n",
    "        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], fill=False, edgecolor='green', linewidth=2))\n",
    "        ax.text(bbox[0], bbox[1] - 4, 'GT_{:s}'.format(row[3]), bbox=dict(facecolor='green', alpha=0.5), fontsize=8, color='white')\n",
    "    ax.set_title(('Image {:s}').format(train_files[j][:-1]), fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_class</th>\n",
       "      <th>image_file</th>\n",
       "      <th>crop_index</th>\n",
       "      <th>crop_class</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>YFT</td>\n",
       "      <td>img_07911.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YFT</td>\n",
       "      <td>724.290780</td>\n",
       "      <td>94.680851</td>\n",
       "      <td>1168.617021</td>\n",
       "      <td>347.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>ALB</td>\n",
       "      <td>img_00003.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NoF</td>\n",
       "      <td>299.452861</td>\n",
       "      <td>26.285698</td>\n",
       "      <td>1168.160268</td>\n",
       "      <td>286.172768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_class     image_file  crop_index crop_class       x_min      y_min  \\\n",
       "4370         YFT  img_07911.jpg         1.0        YFT  724.290780  94.680851   \n",
       "4371         ALB  img_00003.jpg         0.0        NoF  299.452861  26.285698   \n",
       "\n",
       "            x_max        ymax  \n",
       "4370  1168.617021  347.872340  \n",
       "4371  1168.160268  286.172768  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_crop_bboxs_df[4370:4372]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    #resnet50 image preprocessing\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = pre_fn\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FISH_CLASSES.index('NoF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbr_perClass = int(BatchSize / len(FISH_CLASSES))\n",
    "\n",
    "    with self.lock:\n",
    "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "    # The transformation of images is not under thread lock\n",
    "    # so it can be done in parallel\n",
    "    batch_x = np.zeros((BatchSize, ROWS, COLS, 3), dtype=K.floatx())\n",
    "    batch_y = np.zeros((BatchSize, len(FISH_CLASSES)), dtype=K.floatx())\n",
    "    fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nbr_perClass, replace=False),:]\n",
    "    batch_df = GT_crop_bboxs_df.groupby('crop_class', as_index=True).apply(fn)\n",
    "    i = 0\n",
    "    for index,row in batch_df.iterrows():\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(row[0], row[1])\n",
    "        fish = row[3]\n",
    "        bbox = row[4:8]\n",
    "        img = image.load_img(TRAIN_DIR+image_file,target_size=(ROWS,COLS))\n",
    "        x = img_to_array(img, dim_ordering=self.dim_ordering)\n",
    "        x = train_datagen.random_transform(x)\n",
    "        x = train_datagen.standardize(x)\n",
    "        batch_x[i] = x\n",
    "        batch_y[i,FISH_CLASSES.index(fish)] = 1\n",
    "        i += 1\n",
    "    return batch_x, batch_y\n",
    "    \n",
    "def generate_arrays_from_file(path):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            # create numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x, y = process_line(line)\n",
    "            img = load_images(x)\n",
    "            yield (img, y)\n",
    "        f.close()\n",
    "\n",
    "    while 1:\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed + self.total_batches_seen)\n",
    "        if self.batch_index == 0:\n",
    "            index_array = np.arange(n)\n",
    "            if shuffle:\n",
    "                index_array = np.random.permutation(n)\n",
    "\n",
    "        current_index = (self.batch_index * batch_size) % n\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            self.batch_index += 1\n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            self.batch_index = 0\n",
    "        self.total_batches_seen += 1\n",
    "        yield (index_array[current_index: current_index + current_batch_size],\n",
    "               current_index, current_batch_size)\n",
    "        \n",
    "       \n",
    "            \n",
    "model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
    "        samples_per_epoch=10000, nb_epoch=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
