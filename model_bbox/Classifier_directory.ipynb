{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random, glob, pickle, collections, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "TEST_DIR = '../RFCN/JPEGImages/'\n",
    "CHECKPOINT_DIR = './checkpoints/checkpoint4/'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "CONF_THRESH = 0.8\n",
    "# like RCNN expand the crop by 16 pixels\n",
    "p=16\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 128\n",
    "LearningRate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GTbbox_df = ['image_class','image_file','crop_index','crop_class','xmin',''ymin','xmax','ymax']\n",
    "\n",
    "if os.path.exists('../data/GTbbox_df.pickle'):\n",
    "    print ('Loading from file GTbbox_df.pickle.')\n",
    "    GTbbox_df = pd.read_pickle('../data/GTbbox_df.pickle')\n",
    "else:\n",
    "    print ('Generating file GTbbox_df.pickle.'.format(ROWS, COLS))       \n",
    "    GTbbox_df = pd.DataFrame(columns=['image_class','image_file','crop_index','crop_class','xmin','ymin','xmax','ymax'])  \n",
    "\n",
    "    crop_classes=FISH_CLASSES[:]\n",
    "    crop_classes.remove('NoF')\n",
    "\n",
    "    for c in crop_classes:\n",
    "        print(c)\n",
    "        j = json.load(open('../data/BBannotations/{}.json'.format(c), 'r'))\n",
    "        for l in j: \n",
    "            filename = l[\"filename\"]\n",
    "            head, tail = os.path.split(filename)\n",
    "            basename, file_extension = os.path.splitext(tail) \n",
    "            image = Image.open(TRAIN_DIR+c+'/'+tail)\n",
    "            width_image, height_image = image.size\n",
    "            for i in range(len(l[\"annotations\"])):\n",
    "                a = l[\"annotations\"][i]\n",
    "                xmin = (a[\"x\"])\n",
    "                ymin = (a[\"y\"])\n",
    "                width = (a[\"width\"])\n",
    "                height = (a[\"height\"])\n",
    "                delta_width = p/(COLS-2*p)*width\n",
    "                delta_height = p/(ROWS-2*p)*height\n",
    "                xmin_expand = xmin-delta_width\n",
    "                ymin_expand = ymin-delta_height\n",
    "                xmax_expand = xmin+width+delta_width\n",
    "                ymax_expand = ymin+height+delta_height\n",
    "                assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "                assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "                GTbbox_df.loc[len(GTbbox_df)]=[c,tail,i,a[\"class\"],max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "                if a[\"class\"] != c: print(GTbbox_df.tail(1))\n",
    "\n",
    "\n",
    "    #crop NoF by detections_full_AGNOSTICnms.pkl\n",
    "\n",
    "    RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "\n",
    "    with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "        detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    train_detections_full_AGNOSTICnms = detections_full_AGNOSTICnms[1000:]\n",
    "    with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "        train_files = f.readlines()\n",
    "    assert len(train_detections_full_AGNOSTICnms) == len(train_files)\n",
    "\n",
    "\n",
    "    num_NoF_perIm = 10\n",
    "\n",
    "    for im in range(len(train_detections_full_AGNOSTICnms)):\n",
    "        if im%1000 == 0: print(im)\n",
    "\n",
    "        basename = train_files[im][:9]\n",
    "        image_class = train_files[im][10:-1]\n",
    "        image = Image.open(TRAIN_DIR+image_class+'/'+basename+'.jpg')\n",
    "        width_image, height_image = image.size\n",
    "\n",
    "        bboxes = []\n",
    "        detects_im = train_detections_full_AGNOSTICnms[im]\n",
    "        for i in range(len(detects_im)):\n",
    "            if detects_im[i,4] >= 0.999 and detects_im[i,2]<width_image and detects_im[i,3]<height_image:\n",
    "                bboxes.append(detects_im[i,:]) \n",
    "        bboxes = np.asarray(bboxes)\n",
    "        bboxes = bboxes[np.random.choice(bboxes.shape[0], num_NoF_perIm, replace=False), :]\n",
    "\n",
    "        for j in range(len(bboxes)):    \n",
    "            bbox = bboxes[j]\n",
    "            xmin = bbox[0]\n",
    "            ymin = bbox[1]\n",
    "            xmax = bbox[2]\n",
    "            ymax = bbox[3]\n",
    "            width = xmax-xmin\n",
    "            height = ymax-ymin\n",
    "            delta_width = p/(COLS-2*p)*width\n",
    "            delta_height = p/(ROWS-2*p)*height\n",
    "            xmin_expand = xmin-delta_width\n",
    "            ymin_expand = ymin-delta_height\n",
    "            xmax_expand = xmax+delta_width\n",
    "            ymax_expand = ymax+delta_height\n",
    "            assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "            assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "            GTbbox_df.loc[len(GTbbox_df)]=[image_class,basename+'.jpg',j,'NoF',max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "\n",
    "    GTbbox_df.to_pickle('../data/GTbbox_df.pickle')    \n",
    "    \n",
    "train_df, valid_df = train_test_split(GTbbox_df, test_size = 0.2, random_state=1986, stratify=GTbbox_df['crop_class'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#visualization\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_files = f.readlines()\n",
    "\n",
    "for j in range(0,3777,500):\n",
    "    im = Image.open('../RFCN/JPEGImages/'+train_files[j][:9]+'.jpg')\n",
    "    im = np.asarray(im)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    GT_crops = GTbbox_df.loc[GTbbox_df['image_file']==(train_files[j][:9]+'.jpg')]\n",
    "    for index,row in GT_crops.iterrows():\n",
    "        row = row.tolist()\n",
    "        bbox = row[4:8]\n",
    "        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], fill=False, edgecolor='green', linewidth=2))\n",
    "        ax.text(bbox[0], bbox[1] - 4, 'GT_{:s}'.format(row[3]), bbox=dict(facecolor='green', alpha=0.5), fontsize=8, color='white')\n",
    "    ax.set_title(('Image {:s}').format(train_files[j][:-1]), fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for traing and validation data\n",
    "def load_img(path, bbox, target_size=None):\n",
    "    img = Image.open(path)\n",
    "    img = img.convert('RGB')\n",
    "    cropped = img.crop((bbox[0],bbox[1],bbox[2],bbox[3]))\n",
    "    if target_size:\n",
    "        cropped = cropped.resize((target_size[1], target_size[0]))\n",
    "    return cropped\n",
    "\n",
    "def preprocess_input(x):\n",
    "    #resnet50 image preprocessing\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x\n",
    "\n",
    "nb_perClass = int(BatchSize / len(FISH_CLASSES))   \n",
    "samples_per_epoch=BatchSize*math.ceil(train_df.groupby('crop_class').size()['ALB']/nb_perClass)\n",
    "def generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BatchSize, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BatchSize, len(FISH_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('crop_class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(row[0], row[1])\n",
    "            fish = row[3]\n",
    "            bbox = row[4:8]\n",
    "            cropped = load_img(TRAIN_DIR+image_file,bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,FISH_CLASSES.index(fish)] = 1\n",
    "            i += 1\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "generator(datagen=train_datagen, df=train_df)\n",
    "\n",
    "\n",
    "# validation_data (valid_x,valid_y)\n",
    "df_1 = valid_df[valid_df.crop_class != 'NoF']\n",
    "l = valid_df.groupby('crop_class').size()\n",
    "l.pop('NoF')\n",
    "nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "df_2 = valid_df[valid_df.crop_class == 'NoF'].sample(n=nb_NoF_valid)\n",
    "valid_df = pd.concat([df_1,df_2], axis=0)\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(FISH_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = os.path.join(row[0], row[1])\n",
    "    fish = row[3]\n",
    "    bbox = row[4:8]\n",
    "    cropped = load_img(TRAIN_DIR+image_file,bbox,target_size=(ROWS,COLS))\n",
    "    x = np.asarray(cropped, dtype=K.floatx())\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,FISH_CLASSES.index(fish)] = 1\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "        \n",
    "learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs/log4', histogram_freq=0, write_graph=False, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Resnet50\n",
    "#stg1 training\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = LeakyReLU(alpha=0.33)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "x = Dense(256, init='glorot_normal')(x)\n",
    "x = LeakyReLU(alpha=0.33)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(FISH_CLASSES), init='glorot_normal', activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "samples_per_epoch=BatchSize*math.ceil(train_df.groupby('crop_class').size()['ALB']/nb_perClass)\n",
    "model.fit_generator(generator(datagen=train_datagen, df=train_df), samples_per_epoch=samples_per_epoch, nb_epoch=30, verbose=1,\n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=(valid_x,valid_y), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Resnet50\n",
    "#stg4 training\n",
    "\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "# print('Loading model from weights.004-0.0565.hdf5')\n",
    "# model = load_model('./checkpoints/checkpoint3/weights.004-0.0565.hdf5')\n",
    "\n",
    "#164,142,80,38\n",
    "for layer in model.layers[:38]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[38:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "optimizer = Adam(lr=1e-5)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator(datagen=train_datagen, df=train_df), samples_per_epoch=samples_per_epoch, nb_epoch=30, verbose=1,\n",
    "                    callbacks=[early_stopping, model_checkpoint, learningrate_schedule, tensorboard], \n",
    "                    validation_data=(valid_x,valid_y), nb_worker=3, pickle_safe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GTbbox_CROPpred_df = GTbbox_df + ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "# test_data (test_x,test_y)\n",
    "test_x = np.zeros((GTbbox_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "test_y = np.zeros((GTbbox_df.shape[0], len(FISH_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in GTbbox_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = os.path.join(row[0], row[1])\n",
    "    bbox = row[4:8]\n",
    "    cropped = load_img(TRAIN_DIR+image_file,bbox,target_size=(ROWS,COLS))\n",
    "    x = np.asarray(cropped, dtype=K.floatx())\n",
    "    x = preprocess_input(x)\n",
    "    test_x[i] = x\n",
    "    i += 1\n",
    "\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "# print('Loading model from weights.004-0.0565.hdf5')\n",
    "# model = load_model('./checkpoints/checkpoint2/weights.004-0.0565.hdf5')\n",
    "\n",
    "model.predict(x, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RFCNbbox_RFCNpreds_df = ['image_file','crop_index','x_min','y_min','x_max','ymax',\n",
    "#                          'NoF_RFCN', 'ALB_RFCN', 'BET_RFCN', 'DOL_RFCN',\n",
    "#                          'LAG_RFCN', 'OTHER_RFCN', 'SHARK_RFCN', 'YFT_RFCN']\n",
    "if os.path.exists('../data/RFCNbbox_RFCNpreds_df.pickle'):\n",
    "    print ('Loading from file RFCNbbox_RFCNpreds_df.pickle.')\n",
    "    RFCNbbox_RFCNpreds_df = pd.read_pickle('../data/RFCNbbox_RFCNpreds_df.pickle')\n",
    "else:\n",
    "    print ('Generating file RFCNbbox_RFCNpreds_df.pickle.'.format(ROWS, COLS))        \n",
    "    RFCNbbox_RFCNpreds_df = pd.DataFrame(columns=['image_file','crop_index','x_min','y_min','x_max','ymax',\n",
    "                                                  'NoF_RFCN', 'ALB_RFCN', 'BET_RFCN', 'DOL_RFCN',\n",
    "                                                  'LAG_RFCN', 'OTHER_RFCN', 'SHARK_RFCN', 'YFT_RFCN']) \n",
    "\n",
    "    #crop by detections_full_AGNOSTICnms.pkl\n",
    "    RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "    with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "        detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "    with open(\"../RFCN/ImageSets/Main/test.txt\",\"r\") as f:\n",
    "        test_files = f.readlines()\n",
    "    assert len(detections_full_AGNOSTICnms) == len(test_files)\n",
    "\n",
    "    for im in range(len(detections_full_AGNOSTICnms)):\n",
    "        if im%1000 == 0: print(im)\n",
    "        basename = test_files[im][:9]\n",
    "        image = Image.open(TEST_DIR+'/'+basename+'.jpg')\n",
    "        width_image, height_image = image.size\n",
    "        \n",
    "        bboxes = []\n",
    "        detects_im = detections_full_AGNOSTICnms[im]\n",
    "        for i in range(len(detects_im)):\n",
    "            if np.max(detects_im[i,5:]) >= CONF_THRESH:\n",
    "                bboxes.append(detects_im[i,:]) \n",
    "        if len(bboxes) == 0:\n",
    "            ind = np.argmax(np.max(detects_im[:,5:], axis=1))\n",
    "            bboxes.append(detects_im[ind,:])\n",
    "        bboxes = np.asarray(bboxes)\n",
    "\n",
    "        for j in range(len(bboxes)):    \n",
    "            bbox = bboxes[j]\n",
    "            xmin = bbox[0]\n",
    "            ymin = bbox[1]\n",
    "            xmax = bbox[2]\n",
    "            ymax = bbox[3]\n",
    "            width = xmax-xmin\n",
    "            height = ymax-ymin\n",
    "            delta_width = p/(COLS-2*p)*width\n",
    "            delta_height = p/(ROWS-2*p)*height\n",
    "            xmin_expand = xmin-delta_width\n",
    "            ymin_expand = ymin-delta_height\n",
    "            xmax_expand = xmax+delta_width\n",
    "            ymax_expand = ymax+delta_height\n",
    "            assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "            assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "            RFCNbbox_RFCNpreds_df.loc[len(RFCNbbox_RFCNpreds_df)]=[basename+'.jpg',j,max(xmin_expand,0),max(ymin_expand,0),\n",
    "                                                                   min(xmax_expand,width_image),min(ymax_expand,height_image),\n",
    "                                                                   bbox[4],bbox[5],bbox[6],bbox[7],bbox[8],bbox[9],bbox[10],bbox[11]]\n",
    "\n",
    "    RFCNbbox_RFCNpreds_df.to_pickle('../data/RFCNbbox_RFCNpreds_df.pickle')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RFCNbbox_CROPpreds_df = ['image_file','crop_index','x_min','y_min','x_max','ymax',\n",
    "#                          'NoF_RFCN', 'ALB_RFCN', 'BET_RFCN', 'DOL_RFCN',\n",
    "#                          'LAG_RFCN', 'OTHER_RFCN', 'SHARK_RFCN', 'YFT_RFCN']\n",
    "\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "index = val_losses.index(min(val_losses))\n",
    "print('Loading model from checkpoints file ' + files[index])\n",
    "model = load_model(files[index])\n",
    "# print('Loading model from weights.004-0.0565.hdf5')\n",
    "# model = load_model('./checkpoints/checkpoint2/weights.004-0.0565.hdf5')\n",
    "\n",
    "X_test_crop_centered = featurewise_center(X_test_crop)\n",
    "test_crop_preds = model.predict(X_test_crop_centered, batch_size=BatchSize, verbose=1)\n",
    "\n",
    "columns = ['ALB_BBCROP', 'BET_BBCROP', 'DOL_BBCROP', 'LAG_BBCROP', 'NoF_BBCROP', 'OTHER_BBCROP', 'SHARK_BBCROP', 'YFT_BBCROP']\n",
    "BBCROP_preds_df = pd.DataFrame(test_crop_preds, columns=columns)\n",
    "\n",
    "test_crop_files_BBCROP = test_crop_files\n",
    "BBCROP_preds_df.insert(0, 'test_crop_files', test_crop_files_BBCROP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
