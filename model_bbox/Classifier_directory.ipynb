{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random, glob, pickle, collections, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../data/train/'\n",
    "CHECKPOINT_DIR = './checkpoints/checkpoint4/'\n",
    "FISH_CLASSES = ['NoF', 'ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "CONF_THRESH = 0.8\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "BatchSize = 128\n",
    "LearningRate = 1e-4\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# GT_crop_bboxs_df = ['image_class','image_file','crop_index','crop_class','x_min',''y_min','x_max','ymax']\n",
    "# like RCNN expand the crop by 16 pixels\n",
    "p=16        \n",
    "GT_crop_bboxs_df = pd.DataFrame(columns=['image_class','image_file','crop_index','crop_class','x_min','y_min','x_max','ymax'])  \n",
    "\n",
    "crop_classes=FISH_CLASSES[:]\n",
    "crop_classes.remove('NoF')\n",
    "\n",
    "for c in crop_classes:\n",
    "    print(c)\n",
    "    j = json.load(open('../data/BBannotations/{}.json'.format(c), 'r'))\n",
    "    for l in j: \n",
    "        filename = l[\"filename\"]\n",
    "        head, tail = os.path.split(filename)\n",
    "        basename, file_extension = os.path.splitext(tail) \n",
    "        image = Image.open(TRAIN_DIR+c+'/'+tail)\n",
    "        width_image, height_image = image.size\n",
    "        for i in range(len(l[\"annotations\"])):\n",
    "            a = l[\"annotations\"][i]\n",
    "            xmin = (a[\"x\"])\n",
    "            ymin = (a[\"y\"])\n",
    "            width = (a[\"width\"])\n",
    "            height = (a[\"height\"])\n",
    "            delta_width = p/(COLS-2*p)*width\n",
    "            delta_height = p/(ROWS-2*p)*height\n",
    "            xmin_expand = xmin-delta_width\n",
    "            ymin_expand = ymin-delta_height\n",
    "            xmax_expand = xmin+width+delta_width\n",
    "            ymax_expand = ymin+height+delta_height\n",
    "            assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "            assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "            GT_crop_bboxs_df.loc[len(GT_crop_bboxs_df)]=[c,tail,i,a[\"class\"],max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "            if a[\"class\"] != c: print(GT_crop_bboxs_df.tail(1))\n",
    "                \n",
    "\n",
    "#crop NoF by detections_full_AGNOSTICnms.pkl\n",
    "\n",
    "RFCN_MODEL = 'resnet101_rfcn_ohem_iter_30000'\n",
    "\n",
    "with open('../data/RFCN_detections/detections_full_AGNOSTICnms_'+RFCN_MODEL+'.pkl','rb') as f:\n",
    "    detections_full_AGNOSTICnms = pickle.load(f, encoding='latin1') \n",
    "train_detections_full_AGNOSTICnms = detections_full_AGNOSTICnms[1000:]\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_files = f.readlines()\n",
    "assert len(train_detections_full_AGNOSTICnms) == len(train_files)\n",
    "\n",
    "\n",
    "num_NoF_perIm = 10\n",
    "\n",
    "for im in range(len(train_detections_full_AGNOSTICnms)):\n",
    "    if im%1000 == 0: print(im)\n",
    "        \n",
    "    basename = train_files[im][:9]\n",
    "    image_class = train_files[im][10:-1]\n",
    "    image = Image.open(TRAIN_DIR+image_class+'/'+basename+'.jpg')\n",
    "    width_image, height_image = image.size\n",
    "    \n",
    "    bboxes = []\n",
    "    detects_im = train_detections_full_AGNOSTICnms[im]\n",
    "    for i in range(len(detects_im)):\n",
    "        if detects_im[i,4] >= 0.999 and detects_im[i,2]<width_image and detects_im[i,3]<height_image:\n",
    "            bboxes.append(detects_im[i,:]) \n",
    "    bboxes = np.asarray(bboxes)\n",
    "    bboxes = bboxes[np.random.choice(bboxes.shape[0], num_NoF_perIm, replace=False), :]\n",
    "    \n",
    "    for j in range(len(bboxes)):    \n",
    "        bbox = bboxes[j]\n",
    "        xmin = bbox[0]\n",
    "        ymin = bbox[1]\n",
    "        xmax = bbox[2]\n",
    "        ymax = bbox[3]\n",
    "        width = xmax-xmin\n",
    "        height = ymax-ymin\n",
    "        delta_width = p/(COLS-2*p)*width\n",
    "        delta_height = p/(ROWS-2*p)*height\n",
    "        xmin_expand = xmin-delta_width\n",
    "        ymin_expand = ymin-delta_height\n",
    "        xmax_expand = xmax+delta_width\n",
    "        ymax_expand = ymax+delta_height\n",
    "        assert max(xmin_expand,0)<min(xmax_expand,width_image)\n",
    "        assert max(ymin_expand,0)<min(ymax_expand,height_image)\n",
    "        GT_crop_bboxs_df.loc[len(GT_crop_bboxs_df)]=[image_class,basename+'.jpg',j,'NoF',max(xmin_expand,0),max(ymin_expand,0),min(xmax_expand,width_image),min(ymax_expand,height_image)]\n",
    "    \n",
    "GT_crop_bboxs_df.to_pickle('../data/GT_crop_bboxs_df_directory.pickle')                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#visualization\n",
    "\n",
    "with open(\"../RFCN/ImageSets/Main/train_test.txt\",\"r\") as f:\n",
    "    train_files = f.readlines()\n",
    "\n",
    "for j in range(0,3777,500):\n",
    "    im = Image.open('../RFCN/JPEGImages/'+train_files[j][:9]+'.jpg')\n",
    "    im = np.asarray(im)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    GT_crops = GT_crop_bboxs_df.loc[GT_crop_bboxs_df['image_file']==(train_files[j][:9]+'.jpg')]\n",
    "    for index,row in GT_crops.iterrows():\n",
    "        row = row.tolist()\n",
    "        bbox = row[4:8]\n",
    "        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], fill=False, edgecolor='green', linewidth=2))\n",
    "        ax.text(bbox[0], bbox[1] - 4, 'GT_{:s}'.format(row[3]), bbox=dict(facecolor='green', alpha=0.5), fontsize=8, color='white')\n",
    "    ax.set_title(('Image {:s}').format(train_files[j][:-1]), fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_class</th>\n",
       "      <th>image_file</th>\n",
       "      <th>crop_index</th>\n",
       "      <th>crop_class</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>YFT</td>\n",
       "      <td>img_07911.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YFT</td>\n",
       "      <td>724.290780</td>\n",
       "      <td>94.680851</td>\n",
       "      <td>1168.617021</td>\n",
       "      <td>347.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>ALB</td>\n",
       "      <td>img_00003.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NoF</td>\n",
       "      <td>299.452861</td>\n",
       "      <td>26.285698</td>\n",
       "      <td>1168.160268</td>\n",
       "      <td>286.172768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_class     image_file  crop_index crop_class       x_min      y_min  \\\n",
       "4370         YFT  img_07911.jpg         1.0        YFT  724.290780  94.680851   \n",
       "4371         ALB  img_00003.jpg         0.0        NoF  299.452861  26.285698   \n",
       "\n",
       "            x_max        ymax  \n",
       "4370  1168.617021  347.872340  \n",
       "4371  1168.160268  286.172768  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_crop_bboxs_df[4370:4372]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    #resnet50 image preprocessing\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "nbr_perClass = int(BatchSize / len(FISH_CLASSES))   \n",
    "def generator(datagen = train_datagen):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BatchSize, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BatchSize, len(FISH_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nbr_perClass, replace=False),:]\n",
    "        batch_df = GT_crop_bboxs_df.groupby('crop_class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(row[0], row[1])\n",
    "            fish = row[3]\n",
    "            bbox = row[4:8]\n",
    "            img = image.load_img(TRAIN_DIR+image_file,target_size=(ROWS,COLS))\n",
    "            x = img_to_array(img, dim_ordering=self.dim_ordering)\n",
    "            x = train_datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,FISH_CLASSES.index(fish)] = 1\n",
    "            i += 1\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-e4f9694bc79d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# train the model on the new data for a few epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1423\u001b[0m                     raise Exception('output of generator should be a tuple '\n\u001b[1;32m   1424\u001b[0m                                     \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m                                     'or (x, y). Found: ' + str(generator_output))\n\u001b[0m\u001b[1;32m   1426\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\", line 404, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "  File \"<ipython-input-109-66e8a5aeabad>\", line 33, in generator\n",
      "    x = img_to_array(img, dim_ordering=self.dim_ordering)\n",
      "NameError: name 'img_to_array' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Resnet50\n",
    "#stg1 training\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = LeakyReLU(alpha=0.33)(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(256, init='glorot_normal', activation='relu')(x)\n",
    "#x = LeakyReLU(alpha=0.33)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(FISH_CLASSES), init='glorot_normal', activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = Adam(lr=LearningRate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(generator(), samples_per_epoch=BatchSize*2, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
